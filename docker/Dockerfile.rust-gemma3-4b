# TEA-DIST-002: Docker Rust LLM Image - Gemma 3 4B
#
# Full TEA Rust image with bundled Gemma 3 4B GGUF model (~3.3GB).
# Self-contained for offline LLM inference without external model downloads.
#
# Build: docker build -t tea:rust-gemma3-4b -f docker/Dockerfile.rust-gemma3-4b .
# Size: ~4.5GB target
#
# Model: google/gemma-3-4b-it
# Source: Ollama Registry (https://ollama.com/library/gemma3)

# =============================================================================
# Stage 1: Builder - Compile Rust binary with LLM support
# =============================================================================
# NOTE: Model is downloaded directly in final stage to avoid layer duplication
# that would require ~6.6GB during build (3.3GB in downloader + 3.3GB in final)
# =============================================================================
FROM rust:latest AS builder

# Install build dependencies
RUN apt-get update && apt-get install -y --no-install-recommends \
    build-essential \
    pkg-config \
    libssl-dev \
    cmake \
    libclang-dev \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /build

COPY rust/ ./

# Build with all features + scryer + llm-local for embedded inference
RUN cargo build --release --features "memory,trace,data,web,rag,llm,code,agent,reflection,reasoning,planning,a2a,ltm-duckdb,scryer,llm-local"

RUN ls -lh target/release/tea && \
    ./target/release/tea --version

# =============================================================================
# Stage 2: Runtime - Image with bundled model
# =============================================================================
FROM debian:trixie-slim

RUN apt-get update && apt-get install -y --no-install-recommends \
    ca-certificates \
    libssl3t64 \
    libgomp1 \
    curl \
    && apt-get clean \
    && rm -rf /var/lib/apt/lists/* \
    && rm -rf /var/cache/apt/archives/*

# Copy the compiled binary
COPY --from=builder /build/target/release/tea /usr/local/bin/tea

# Download model directly in final stage to avoid layer duplication
# This saves ~3.3GB of overlay storage during build
RUN mkdir -p /opt/tea-models && \
    curl -L -o /opt/tea-models/gemma3-4b.gguf \
    "https://registry.ollama.ai/v2/library/gemma3/blobs/sha256:aeda25e63ebd698fab8638ffb778e68bed908b960d39d0becc650fa981609d25" && \
    ls -lh /opt/tea-models/ && \
    test -f /opt/tea-models/gemma3-4b.gguf

# Verify binary
RUN tea --version

# Set environment variables for model
ENV TEA_MODEL_PATH="/opt/tea-models/gemma3-4b.gguf"
ENV TEA_MODEL_NAME="gemma3-4b"

# Create non-root user for security
RUN useradd -m -s /bin/bash tea \
    && mkdir -p /home/tea/.tea \
    && chown -R tea:tea /home/tea

USER tea
WORKDIR /work

# Labels for container registry
LABEL org.opencontainers.image.source="https://github.com/fabceolin/the_edge_agent"
LABEL org.opencontainers.image.description="TEA Rust Gemma3-4B - Full features with bundled Gemma 3 4B model"
LABEL org.opencontainers.image.licenses="MIT"
LABEL tea.variant="rust-gemma3-4b"
LABEL tea.runtime="rust"
LABEL tea.model="gemma3-4b"
LABEL tea.model.size="3.3GB"
LABEL tea.model.source="ollama"

ENTRYPOINT ["tea"]
CMD ["--help"]
