# =============================================================================
# Build Rust LLM - Reusable Workflow
# =============================================================================
# Purpose: Builds 6 Rust LLM binaries and AppImages
#   - Linux x86_64 LLM binary (Vulkan + OpenMP)
#   - Linux ARM64 LLM binary (Vulkan + OpenMP)
#   - Linux x86_64 LLM AppImage (Phi-4 model)
#   - Linux ARM64 LLM AppImage (Phi-4 model)
#   - Linux x86_64 LLM AppImage (Gemma 3 1B model)
#   - Linux ARM64 LLM AppImage (Gemma 3 1B model)
#
# Inputs:
#   - ref: Git ref to build (default: github.ref)
#
# Outputs:
#   - Artifacts: rust-tea-rust-linux-x86_64-llm, llm-appimage-phi4-x86_64, etc.
#
# Part of Story: TEA-RELEASE-005 (Workflow Modularization)
# =============================================================================

name: Build Rust LLM

on:
  workflow_call:
    inputs:
      ref:
        description: 'Git ref to build'
        type: string
        required: false
        default: ''
  workflow_dispatch:
    inputs:
      ref:
        description: 'Git ref to build (leave empty for current branch)'
        type: string
        required: false
        default: ''

jobs:
  # ============================================================
  # Rust LLM Binary - x86_64
  # ============================================================
  build-rust-llm-linux-x86_64:
    runs-on: ubuntu-24.04
    name: Rust linux-x86_64-llm

    steps:
      - uses: actions/checkout@v4
        with:
          ref: ${{ inputs.ref || github.ref }}

      - name: Install build dependencies (OpenMP + Vulkan)
        run: |
          sudo apt-get update
          # OpenMP comes with GCC (build-essential), no separate libgomp-dev needed
          sudo apt-get install -y build-essential cmake pkg-config \
            libvulkan-dev glslang-tools glslc

      - name: Setup Rust
        uses: dtolnay/rust-toolchain@stable

      - name: Cache cargo registry
        uses: actions/cache@v4
        with:
          path: |
            ~/.cargo/registry
            ~/.cargo/git
            rust/target
          key: ${{ runner.os }}-x86_64-llm-cargo-${{ hashFiles('rust/Cargo.lock') }}
          restore-keys: |
            ${{ runner.os }}-x86_64-llm-cargo-

      - name: Build release binary with LLM feature
        run: |
          cd rust
          cargo build --release --features llm-local-vulkan --bin tea

      - name: Copy binary
        run: |
          cp rust/target/release/tea tea-rust-linux-x86_64-llm

      - name: Set executable permission
        run: chmod +x tea-rust-linux-x86_64-llm

      - name: Smoke test - version
        run: ./tea-rust-linux-x86_64-llm --version

      - name: Smoke test - impl
        run: |
          impl=$(./tea-rust-linux-x86_64-llm --impl)
          if [ "$impl" != "rust" ]; then
            echo "Error: Expected 'rust', got '$impl'"
            exit 1
          fi

      - name: Check binary size
        run: |
          size=$(stat -c%s "tea-rust-linux-x86_64-llm")
          size_mb=$((size / 1024 / 1024))
          echo "Binary size: ${size_mb}MB"

      - name: Upload artifact
        uses: actions/upload-artifact@v4
        with:
          name: rust-tea-rust-linux-x86_64-llm
          path: tea-rust-linux-x86_64-llm
          retention-days: 1

  # ============================================================
  # Rust LLM Binary - ARM64
  # ============================================================
  build-rust-llm-linux-arm64:
    runs-on: ubuntu-24.04-arm
    name: Rust linux-arm64-llm

    steps:
      - uses: actions/checkout@v4
        with:
          ref: ${{ inputs.ref || github.ref }}

      - name: Install build dependencies (OpenMP + Vulkan)
        run: |
          sudo apt-get update
          # OpenMP comes with GCC (build-essential), no separate libgomp-dev needed
          sudo apt-get install -y build-essential cmake pkg-config \
            libvulkan-dev glslang-tools glslc

      - name: Setup Rust
        uses: dtolnay/rust-toolchain@stable

      - name: Cache cargo registry
        uses: actions/cache@v4
        with:
          path: |
            ~/.cargo/registry
            ~/.cargo/git
            rust/target
          key: ${{ runner.os }}-arm64-llm-cargo-${{ hashFiles('rust/Cargo.lock') }}
          restore-keys: |
            ${{ runner.os }}-arm64-llm-cargo-

      - name: Build release binary with LLM feature
        run: |
          cd rust
          cargo build --release --features llm-local-vulkan --bin tea

      - name: Copy binary
        run: |
          cp rust/target/release/tea tea-rust-linux-arm64-llm

      - name: Set executable permission
        run: chmod +x tea-rust-linux-arm64-llm

      - name: Smoke test - version
        run: ./tea-rust-linux-arm64-llm --version

      - name: Smoke test - impl
        run: |
          impl=$(./tea-rust-linux-arm64-llm --impl)
          if [ "$impl" != "rust" ]; then
            echo "Error: Expected 'rust', got '$impl'"
            exit 1
          fi

      - name: Check binary size
        run: |
          size=$(stat -c%s "tea-rust-linux-arm64-llm")
          size_mb=$((size / 1024 / 1024))
          echo "Binary size: ${size_mb}MB"

      - name: Upload artifact
        uses: actions/upload-artifact@v4
        with:
          name: rust-tea-rust-linux-arm64-llm
          path: tea-rust-linux-arm64-llm
          retention-days: 1

  # ============================================================
  # Phi-4-mini LLM AppImage for x86_64 (~2.5GB, compact)
  # ============================================================
  build-rust-llm-phi4-appimage-x86_64:
    runs-on: ubuntu-24.04
    needs: [build-rust-llm-linux-x86_64]
    name: Rust LLM AppImage x86_64 (Phi-4)

    steps:
      - uses: actions/checkout@v4
        with:
          ref: ${{ inputs.ref || github.ref }}

      - name: Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y file libfuse2 libgomp1

      - name: Download LLM binary
        uses: actions/download-artifact@v4
        with:
          name: rust-tea-rust-linux-x86_64-llm
          path: .

      - name: Download linuxdeploy
        run: |
          wget -q https://github.com/linuxdeploy/linuxdeploy/releases/download/continuous/linuxdeploy-x86_64.AppImage
          chmod +x linuxdeploy-x86_64.AppImage

      - name: Download Phi-4-mini model from HuggingFace
        run: |
          mkdir -p models
          echo "Downloading Phi-4-mini Q3_K_S model (~1.9GB)..."
          wget -q --show-progress \
            "https://huggingface.co/bartowski/microsoft_Phi-4-mini-instruct-GGUF/resolve/main/microsoft_Phi-4-mini-instruct-Q3_K_S.gguf" \
            -O models/microsoft_Phi-4-mini-instruct-Q3_K_S.gguf
          ls -lh models/

      - name: Create .desktop file
        run: |
          cat > tea-llm.desktop << 'EOF'
          [Desktop Entry]
          Name=TEA LLM Rust Phi4
          Comment=Lightweight state graph workflow engine with local LLM
          Exec=tea
          Icon=tea
          Type=Application
          Categories=Development;
          Terminal=true
          EOF
          sed -i 's/^[[:space:]]*//' tea-llm.desktop

      - name: Create placeholder icon
        run: |
          cat > tea.svg << 'EOF'
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 256">
            <rect width="256" height="256" fill="#2d3748"/>
            <text x="128" y="160" font-family="monospace" font-size="120" fill="#48bb78" text-anchor="middle">t</text>
          </svg>
          EOF

      - name: Create AppDir structure
        run: |
          mkdir -p tea-llm.AppDir/usr/bin
          mkdir -p tea-llm.AppDir/usr/lib
          mkdir -p tea-llm.AppDir/usr/share/models
          chmod +x tea-rust-linux-x86_64-llm
          cp tea-rust-linux-x86_64-llm tea-llm.AppDir/usr/bin/tea
          cp models/microsoft_Phi-4-mini-instruct-Q3_K_S.gguf tea-llm.AppDir/usr/share/models/

          # Bundle libgomp for OpenMP portability
          LIBGOMP_PATH=$(find /usr -name 'libgomp.so.1' 2>/dev/null | head -1)
          if [ -n "$LIBGOMP_PATH" ]; then
            cp "$LIBGOMP_PATH" tea-llm.AppDir/usr/lib/
            echo "Bundled libgomp from: $LIBGOMP_PATH"
          else
            echo "Warning: libgomp.so.1 not found"
          fi

      - name: Run linuxdeploy
        run: |
          ./linuxdeploy-x86_64.AppImage \
            --appdir tea-llm.AppDir \
            --executable tea-llm.AppDir/usr/bin/tea \
            --desktop-file tea-llm.desktop \
            --icon-file tea.svg \
            --output appimage

      - name: Create custom AppRun
        run: |
          rm -f tea-llm.AppDir/AppRun
          cat > tea-llm.AppDir/AppRun << 'EOF'
          #!/bin/bash
          HERE="$(dirname "$(readlink -f "${0}")")"
          export LD_LIBRARY_PATH="${HERE}/usr/lib:${LD_LIBRARY_PATH}"
          # Auto-detect model in bundled models directory
          if [ -z "$TEA_MODEL_PATH" ]; then
            MODEL_FILE=$(find "${HERE}/usr/share/models" -name "*.gguf" -type f | head -1)
            if [ -n "$MODEL_FILE" ]; then
              export TEA_MODEL_PATH="$MODEL_FILE"
            fi
          fi
          exec "${HERE}/usr/bin/tea" "$@"
          EOF
          chmod +x tea-llm.AppDir/AppRun

      - name: Rebuild AppImage with custom AppRun
        run: |
          VERSION="${GITHUB_REF_NAME#v}"
          if [ -z "$VERSION" ] || [ "$VERSION" = "$GITHUB_REF_NAME" ]; then
            VERSION="dev"
          fi
          wget -q https://github.com/AppImage/AppImageKit/releases/download/continuous/appimagetool-x86_64.AppImage
          chmod +x appimagetool-x86_64.AppImage
          ARCH=x86_64 ./appimagetool-x86_64.AppImage tea-llm.AppDir "tea-rust-llm-phi4-${VERSION}-x86_64.AppImage"

      - name: Smoke test AppImage
        run: |
          chmod +x tea-rust-llm-phi4-*-x86_64.AppImage
          ./tea-rust-llm-phi4-*-x86_64.AppImage --version
          impl=$(./tea-rust-llm-phi4-*-x86_64.AppImage --impl)
          if [ "$impl" != "rust" ]; then
            echo "Error: Expected 'rust', got '$impl'"
            exit 1
          fi

      - name: Check AppImage size
        run: |
          size=$(stat -c%s tea-rust-llm-phi4-*-x86_64.AppImage)
          size_mb=$((size / 1024 / 1024))
          echo "AppImage size: ${size_mb}MB"

      - name: Upload artifact
        uses: actions/upload-artifact@v4
        with:
          name: llm-appimage-phi4-x86_64
          path: tea-rust-llm-phi4-*-x86_64.AppImage
          retention-days: 1

  # ============================================================
  # Phi-4-mini LLM AppImage for ARM64 (~2.5GB, compact)
  # ============================================================
  build-rust-llm-phi4-appimage-aarch64:
    runs-on: ubuntu-24.04-arm
    needs: [build-rust-llm-linux-arm64]
    name: Rust LLM AppImage aarch64 (Phi-4)

    steps:
      - uses: actions/checkout@v4
        with:
          ref: ${{ inputs.ref || github.ref }}

      - name: Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y file libfuse2 libgomp1

      - name: Download LLM binary
        uses: actions/download-artifact@v4
        with:
          name: rust-tea-rust-linux-arm64-llm
          path: .

      - name: Download linuxdeploy
        run: |
          wget -q https://github.com/linuxdeploy/linuxdeploy/releases/download/continuous/linuxdeploy-aarch64.AppImage
          chmod +x linuxdeploy-aarch64.AppImage

      - name: Download Phi-4-mini model from HuggingFace
        run: |
          mkdir -p models
          echo "Downloading Phi-4-mini Q3_K_S model (~1.9GB)..."
          wget -q --show-progress \
            "https://huggingface.co/bartowski/microsoft_Phi-4-mini-instruct-GGUF/resolve/main/microsoft_Phi-4-mini-instruct-Q3_K_S.gguf" \
            -O models/microsoft_Phi-4-mini-instruct-Q3_K_S.gguf
          ls -lh models/

      - name: Create .desktop file
        run: |
          cat > tea-llm.desktop << 'EOF'
          [Desktop Entry]
          Name=TEA LLM Rust Phi4
          Comment=Lightweight state graph workflow engine with local LLM
          Exec=tea
          Icon=tea
          Type=Application
          Categories=Development;
          Terminal=true
          EOF
          sed -i 's/^[[:space:]]*//' tea-llm.desktop

      - name: Create placeholder icon
        run: |
          cat > tea.svg << 'EOF'
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 256">
            <rect width="256" height="256" fill="#2d3748"/>
            <text x="128" y="160" font-family="monospace" font-size="120" fill="#48bb78" text-anchor="middle">t</text>
          </svg>
          EOF

      - name: Create AppDir structure
        run: |
          mkdir -p tea-llm.AppDir/usr/bin
          mkdir -p tea-llm.AppDir/usr/lib
          mkdir -p tea-llm.AppDir/usr/share/models
          chmod +x tea-rust-linux-arm64-llm
          cp tea-rust-linux-arm64-llm tea-llm.AppDir/usr/bin/tea
          cp models/microsoft_Phi-4-mini-instruct-Q3_K_S.gguf tea-llm.AppDir/usr/share/models/

          # Bundle libgomp for OpenMP portability
          LIBGOMP_PATH=$(find /usr -name 'libgomp.so.1' 2>/dev/null | head -1)
          if [ -n "$LIBGOMP_PATH" ]; then
            cp "$LIBGOMP_PATH" tea-llm.AppDir/usr/lib/
            echo "Bundled libgomp from: $LIBGOMP_PATH"
          else
            echo "Warning: libgomp.so.1 not found"
          fi

      - name: Run linuxdeploy
        run: |
          ./linuxdeploy-aarch64.AppImage \
            --appdir tea-llm.AppDir \
            --executable tea-llm.AppDir/usr/bin/tea \
            --desktop-file tea-llm.desktop \
            --icon-file tea.svg \
            --output appimage

      - name: Create custom AppRun
        run: |
          rm -f tea-llm.AppDir/AppRun
          cat > tea-llm.AppDir/AppRun << 'EOF'
          #!/bin/bash
          HERE="$(dirname "$(readlink -f "${0}")")"
          export LD_LIBRARY_PATH="${HERE}/usr/lib:${LD_LIBRARY_PATH}"
          # Auto-detect model in bundled models directory
          if [ -z "$TEA_MODEL_PATH" ]; then
            MODEL_FILE=$(find "${HERE}/usr/share/models" -name "*.gguf" -type f | head -1)
            if [ -n "$MODEL_FILE" ]; then
              export TEA_MODEL_PATH="$MODEL_FILE"
            fi
          fi
          exec "${HERE}/usr/bin/tea" "$@"
          EOF
          chmod +x tea-llm.AppDir/AppRun

      - name: Rebuild AppImage with custom AppRun
        run: |
          VERSION="${GITHUB_REF_NAME#v}"
          if [ -z "$VERSION" ] || [ "$VERSION" = "$GITHUB_REF_NAME" ]; then
            VERSION="dev"
          fi
          wget -q https://github.com/AppImage/AppImageKit/releases/download/continuous/appimagetool-aarch64.AppImage
          chmod +x appimagetool-aarch64.AppImage
          ARCH=aarch64 ./appimagetool-aarch64.AppImage tea-llm.AppDir "tea-rust-llm-phi4-${VERSION}-aarch64.AppImage"

      - name: Smoke test AppImage
        run: |
          chmod +x tea-rust-llm-phi4-*-aarch64.AppImage
          ./tea-rust-llm-phi4-*-aarch64.AppImage --version
          impl=$(./tea-rust-llm-phi4-*-aarch64.AppImage --impl)
          if [ "$impl" != "rust" ]; then
            echo "Error: Expected 'rust', got '$impl'"
            exit 1
          fi

      - name: Check AppImage size
        run: |
          size=$(stat -c%s tea-rust-llm-phi4-*-aarch64.AppImage)
          size_mb=$((size / 1024 / 1024))
          echo "AppImage size: ${size_mb}MB"

      - name: Upload artifact
        uses: actions/upload-artifact@v4
        with:
          name: llm-appimage-phi4-aarch64
          path: tea-rust-llm-phi4-*-aarch64.AppImage
          retention-days: 1

  # ============================================================
  # Gemma 3 1B LLM AppImage for x86_64 (~1.5GB, ultra-lightweight)
  # ============================================================
  build-rust-llm-gemma3-1b-appimage-x86_64:
    runs-on: ubuntu-24.04
    needs: [build-rust-llm-linux-x86_64]
    name: Rust LLM AppImage x86_64 (Gemma3-1B)

    steps:
      - uses: actions/checkout@v4
        with:
          ref: ${{ inputs.ref || github.ref }}

      - name: Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y file libfuse2 libgomp1

      - name: Download LLM binary
        uses: actions/download-artifact@v4
        with:
          name: rust-tea-rust-linux-x86_64-llm
          path: .

      - name: Download linuxdeploy
        run: |
          wget -q https://github.com/linuxdeploy/linuxdeploy/releases/download/continuous/linuxdeploy-x86_64.AppImage
          chmod +x linuxdeploy-x86_64.AppImage

      - name: Download Gemma 3 1B model from HuggingFace
        run: |
          mkdir -p models
          echo "Downloading Gemma 3 1B Q8_0 model (~1.07GB)..."
          wget -q --show-progress \
            "https://huggingface.co/unsloth/gemma-3-1b-it-GGUF/resolve/main/gemma-3-1b-it-Q8_0.gguf" \
            -O models/gemma-3-1b-it-Q8_0.gguf
          ls -lh models/

      - name: Create .desktop file
        run: |
          cat > tea-llm.desktop << 'EOF'
          [Desktop Entry]
          Name=TEA LLM Rust Gemma3-1B
          Comment=Lightweight state graph workflow engine with local LLM
          Exec=tea
          Icon=tea
          Type=Application
          Categories=Development;
          Terminal=true
          EOF
          sed -i 's/^[[:space:]]*//' tea-llm.desktop

      - name: Create placeholder icon
        run: |
          cat > tea.svg << 'EOF'
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 256">
            <rect width="256" height="256" fill="#2d3748"/>
            <text x="128" y="160" font-family="monospace" font-size="120" fill="#48bb78" text-anchor="middle">t</text>
          </svg>
          EOF

      - name: Create AppDir structure
        run: |
          mkdir -p tea-llm.AppDir/usr/bin
          mkdir -p tea-llm.AppDir/usr/lib
          mkdir -p tea-llm.AppDir/usr/share/models
          chmod +x tea-rust-linux-x86_64-llm
          cp tea-rust-linux-x86_64-llm tea-llm.AppDir/usr/bin/tea
          cp models/gemma-3-1b-it-Q8_0.gguf tea-llm.AppDir/usr/share/models/

          # Bundle libgomp for OpenMP portability
          LIBGOMP_PATH=$(find /usr -name 'libgomp.so.1' 2>/dev/null | head -1)
          if [ -n "$LIBGOMP_PATH" ]; then
            cp "$LIBGOMP_PATH" tea-llm.AppDir/usr/lib/
            echo "Bundled libgomp from: $LIBGOMP_PATH"
          else
            echo "Warning: libgomp.so.1 not found"
          fi

      - name: Run linuxdeploy
        run: |
          ./linuxdeploy-x86_64.AppImage \
            --appdir tea-llm.AppDir \
            --executable tea-llm.AppDir/usr/bin/tea \
            --desktop-file tea-llm.desktop \
            --icon-file tea.svg \
            --output appimage

      - name: Create custom AppRun
        run: |
          rm -f tea-llm.AppDir/AppRun
          cat > tea-llm.AppDir/AppRun << 'EOF'
          #!/bin/bash
          HERE="$(dirname "$(readlink -f "${0}")")"
          export LD_LIBRARY_PATH="${HERE}/usr/lib:${LD_LIBRARY_PATH}"
          # Auto-detect model in bundled models directory
          if [ -z "$TEA_MODEL_PATH" ]; then
            MODEL_FILE=$(find "${HERE}/usr/share/models" -name "*.gguf" -type f | head -1)
            if [ -n "$MODEL_FILE" ]; then
              export TEA_MODEL_PATH="$MODEL_FILE"
            fi
          fi
          exec "${HERE}/usr/bin/tea" "$@"
          EOF
          chmod +x tea-llm.AppDir/AppRun

      - name: Rebuild AppImage with custom AppRun
        run: |
          VERSION="${GITHUB_REF_NAME#v}"
          if [ -z "$VERSION" ] || [ "$VERSION" = "$GITHUB_REF_NAME" ]; then
            VERSION="dev"
          fi
          wget -q https://github.com/AppImage/AppImageKit/releases/download/continuous/appimagetool-x86_64.AppImage
          chmod +x appimagetool-x86_64.AppImage
          ARCH=x86_64 ./appimagetool-x86_64.AppImage tea-llm.AppDir "tea-rust-llm-gemma3-1b-${VERSION}-x86_64.AppImage"

      - name: Smoke test AppImage
        run: |
          chmod +x tea-rust-llm-gemma3-1b-*-x86_64.AppImage
          ./tea-rust-llm-gemma3-1b-*-x86_64.AppImage --version
          impl=$(./tea-rust-llm-gemma3-1b-*-x86_64.AppImage --impl)
          if [ "$impl" != "rust" ]; then
            echo "Error: Expected 'rust', got '$impl'"
            exit 1
          fi

      # TEA-RUST-045: Smoke test for llm.embed action
      - name: Smoke test embedding (TEA-RUST-045)
        run: |
          # Create a simple embedding workflow
          cat > test-embed.yaml << 'EOF'
          name: test-embedding
          state_schema:
            text: str
            embedding: list
            dimensions: int

          initial_state:
            text: "Hello world"

          nodes:
            - name: embed
              uses: llm.embed
              with:
                text: "{{ state.text }}"
              outputs:
                embedding: embedding
                dimensions: dimensions

          edges:
            - from: __start__
              to: embed
            - from: embed
              to: __end__
          EOF

          # Run the workflow and capture output
          output=$(./tea-rust-llm-gemma3-1b-*-x86_64.AppImage run test-embed.yaml 2>&1)
          echo "$output"

          # Verify embedding was generated (look for dimensions in output)
          if echo "$output" | grep -q '"dimensions"'; then
            echo "✓ Embedding smoke test passed"
          else
            echo "✗ Embedding smoke test failed - no dimensions found"
            exit 1
          fi

          # Cleanup
          rm -f test-embed.yaml

      - name: Check AppImage size
        run: |
          size=$(stat -c%s tea-rust-llm-gemma3-1b-*-x86_64.AppImage)
          size_mb=$((size / 1024 / 1024))
          echo "AppImage size: ${size_mb}MB"

      - name: Upload artifact
        uses: actions/upload-artifact@v4
        with:
          name: llm-appimage-gemma3-1b-x86_64
          path: tea-rust-llm-gemma3-1b-*-x86_64.AppImage
          retention-days: 1

  # ============================================================
  # Gemma 3 1B LLM AppImage for ARM64 (~1.5GB, ultra-lightweight)
  # ============================================================
  build-rust-llm-gemma3-1b-appimage-aarch64:
    runs-on: ubuntu-24.04-arm
    needs: [build-rust-llm-linux-arm64]
    name: Rust LLM AppImage aarch64 (Gemma3-1B)

    steps:
      - uses: actions/checkout@v4
        with:
          ref: ${{ inputs.ref || github.ref }}

      - name: Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y file libfuse2 libgomp1

      - name: Download LLM binary
        uses: actions/download-artifact@v4
        with:
          name: rust-tea-rust-linux-arm64-llm
          path: .

      - name: Download linuxdeploy
        run: |
          wget -q https://github.com/linuxdeploy/linuxdeploy/releases/download/continuous/linuxdeploy-aarch64.AppImage
          chmod +x linuxdeploy-aarch64.AppImage

      - name: Download Gemma 3 1B model from HuggingFace
        run: |
          mkdir -p models
          echo "Downloading Gemma 3 1B Q8_0 model (~1.07GB)..."
          wget -q --show-progress \
            "https://huggingface.co/unsloth/gemma-3-1b-it-GGUF/resolve/main/gemma-3-1b-it-Q8_0.gguf" \
            -O models/gemma-3-1b-it-Q8_0.gguf
          ls -lh models/

      - name: Create .desktop file
        run: |
          cat > tea-llm.desktop << 'EOF'
          [Desktop Entry]
          Name=TEA LLM Rust Gemma3-1B
          Comment=Lightweight state graph workflow engine with local LLM
          Exec=tea
          Icon=tea
          Type=Application
          Categories=Development;
          Terminal=true
          EOF
          sed -i 's/^[[:space:]]*//' tea-llm.desktop

      - name: Create placeholder icon
        run: |
          cat > tea.svg << 'EOF'
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 256">
            <rect width="256" height="256" fill="#2d3748"/>
            <text x="128" y="160" font-family="monospace" font-size="120" fill="#48bb78" text-anchor="middle">t</text>
          </svg>
          EOF

      - name: Create AppDir structure
        run: |
          mkdir -p tea-llm.AppDir/usr/bin
          mkdir -p tea-llm.AppDir/usr/lib
          mkdir -p tea-llm.AppDir/usr/share/models
          chmod +x tea-rust-linux-arm64-llm
          cp tea-rust-linux-arm64-llm tea-llm.AppDir/usr/bin/tea
          cp models/gemma-3-1b-it-Q8_0.gguf tea-llm.AppDir/usr/share/models/

          # Bundle libgomp for OpenMP portability
          LIBGOMP_PATH=$(find /usr -name 'libgomp.so.1' 2>/dev/null | head -1)
          if [ -n "$LIBGOMP_PATH" ]; then
            cp "$LIBGOMP_PATH" tea-llm.AppDir/usr/lib/
            echo "Bundled libgomp from: $LIBGOMP_PATH"
          else
            echo "Warning: libgomp.so.1 not found"
          fi

      - name: Run linuxdeploy
        run: |
          ./linuxdeploy-aarch64.AppImage \
            --appdir tea-llm.AppDir \
            --executable tea-llm.AppDir/usr/bin/tea \
            --desktop-file tea-llm.desktop \
            --icon-file tea.svg \
            --output appimage

      - name: Create custom AppRun
        run: |
          rm -f tea-llm.AppDir/AppRun
          cat > tea-llm.AppDir/AppRun << 'EOF'
          #!/bin/bash
          HERE="$(dirname "$(readlink -f "${0}")")"
          export LD_LIBRARY_PATH="${HERE}/usr/lib:${LD_LIBRARY_PATH}"
          # Auto-detect model in bundled models directory
          if [ -z "$TEA_MODEL_PATH" ]; then
            MODEL_FILE=$(find "${HERE}/usr/share/models" -name "*.gguf" -type f | head -1)
            if [ -n "$MODEL_FILE" ]; then
              export TEA_MODEL_PATH="$MODEL_FILE"
            fi
          fi
          exec "${HERE}/usr/bin/tea" "$@"
          EOF
          chmod +x tea-llm.AppDir/AppRun

      - name: Rebuild AppImage with custom AppRun
        run: |
          VERSION="${GITHUB_REF_NAME#v}"
          if [ -z "$VERSION" ] || [ "$VERSION" = "$GITHUB_REF_NAME" ]; then
            VERSION="dev"
          fi
          wget -q https://github.com/AppImage/AppImageKit/releases/download/continuous/appimagetool-aarch64.AppImage
          chmod +x appimagetool-aarch64.AppImage
          ARCH=aarch64 ./appimagetool-aarch64.AppImage tea-llm.AppDir "tea-rust-llm-gemma3-1b-${VERSION}-aarch64.AppImage"

      - name: Smoke test AppImage
        run: |
          chmod +x tea-rust-llm-gemma3-1b-*-aarch64.AppImage
          ./tea-rust-llm-gemma3-1b-*-aarch64.AppImage --version
          impl=$(./tea-rust-llm-gemma3-1b-*-aarch64.AppImage --impl)
          if [ "$impl" != "rust" ]; then
            echo "Error: Expected 'rust', got '$impl'"
            exit 1
          fi

      # TEA-RUST-045: Smoke test for llm.embed action
      - name: Smoke test embedding (TEA-RUST-045)
        run: |
          # Create a simple embedding workflow
          cat > test-embed.yaml << 'EOF'
          name: test-embedding
          state_schema:
            text: str
            embedding: list
            dimensions: int

          initial_state:
            text: "Hello world"

          nodes:
            - name: embed
              uses: llm.embed
              with:
                text: "{{ state.text }}"
              outputs:
                embedding: embedding
                dimensions: dimensions

          edges:
            - from: __start__
              to: embed
            - from: embed
              to: __end__
          EOF

          # Run the workflow and capture output
          output=$(./tea-rust-llm-gemma3-1b-*-aarch64.AppImage run test-embed.yaml 2>&1)
          echo "$output"

          # Verify embedding was generated (look for dimensions in output)
          if echo "$output" | grep -q '"dimensions"'; then
            echo "✓ Embedding smoke test passed"
          else
            echo "✗ Embedding smoke test failed - no dimensions found"
            exit 1
          fi

          # Cleanup
          rm -f test-embed.yaml

      - name: Check AppImage size
        run: |
          size=$(stat -c%s tea-rust-llm-gemma3-1b-*-aarch64.AppImage)
          size_mb=$((size / 1024 / 1024))
          echo "AppImage size: ${size_mb}MB"

      - name: Upload artifact
        uses: actions/upload-artifact@v4
        with:
          name: llm-appimage-gemma3-1b-aarch64
          path: tea-rust-llm-gemma3-1b-*-aarch64.AppImage
          retention-days: 1
