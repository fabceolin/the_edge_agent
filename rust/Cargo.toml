[package]
name = "the_edge_agent"
version = "0.9.75"
edition = "2021"
authors = ["The Edge Agent Contributors"]
description = "Lightweight state graph workflow engine for edge computing"
license = "MIT"
readme = "README.md"
repository = "https://github.com/fabceolin/the_edge_agent"
keywords = ["workflow", "state-machine", "graph", "edge-computing", "lua"]
categories = ["development-tools", "command-line-utilities"]

[lib]
name = "the_edge_agent"
path = "src/lib.rs"

[[bin]]
name = "tea"
path = "src/bin/tea.rs"

[dependencies]
# Core graph data structure
petgraph = "0.6"

# Serialization
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
serde_yaml = "0.9"
rmp-serde = "1.3"  # MessagePack - self-describing binary format (like pickle)

# Template engine (Jinja-like syntax)
tera = "1.19"

# Lua scripting
mlua = { version = "0.9", features = ["lua54", "vendored", "serialize"] }

# Parallel execution
rayon = "1.10"
crossbeam = "0.8"

# HTTP client (blocking for simplicity)
# NOTE: rustls-tls is needed for HTTPS; for local HTTP (e.g., Ollama), plain HTTP works
reqwest = { version = "0.12", features = ["blocking", "json", "rustls-tls"], default-features = false }

# CLI
clap = { version = "4.5", features = ["derive"] }

# Signal handling for interactive mode (TEA-CLI-005b)
ctrlc = "3.4"

# Error handling
thiserror = "2.0"
anyhow = "1.0"

# Logging and tracing
log = "0.4"
tracing = "0.1"
tracing-subscriber = { version = "0.3", features = ["env-filter", "json"] }

# Utilities
parking_lot = "0.12"
uuid = { version = "1.11", features = ["v4", "v7", "serde"] }
shellexpand = "3.1"  # TEA-CLI-001: Path expansion for --gguf
chrono = { version = "0.4", features = ["serde"] }
rand = "0.8"
regex = "1"
backtrace = "0.3"  # TEA-REPORT-001a: Stack trace capture for error reports
dirs = "5.0"  # TEA-REPORT-001a: Home directory detection for path sanitization
flate2 = "1.0"  # TEA-REPORT-001b: Deflate compression for URL encoding
base64 = "0.22"  # TEA-REPORT-001b: Base64url encoding for URL encoding

# A2A Inter-Agent Communication (optional)
dashmap = { version = "6.1", optional = true }
bincode = { version = "1.3", optional = true }

# Data processing
csv = "1.3"
jmespath = "0.3"
jsonschema = "0.24"

# Markdown parsing (TEA-RALPHY-001.2)
md-parser = { git = "https://github.com/fabceolin/md-parser", features = ["serde", "frontmatter"], optional = true }

# Async runtime (for HTTP)
tokio = { version = "1", features = ["rt", "macros"] }

[dev-dependencies]
# Testing
tempfile = "3.14"
pretty_assertions = "1.4"
criterion = "0.5"
assert_cmd = "2.0"
predicates = "3.1"

[features]
default = ["memory", "trace", "data", "llm", "agent", "reflection", "reasoning", "planning", "markdown"]
memory = []
trace = []
data = []
web = []
rag = []
llm = []
code = []
agent = []  # Multi-agent collaboration primitives (TEA-AGENT-001.1-rust)
reflection = []  # Reflection loop primitives (TEA-AGENT-001.2-rust)
reasoning = ["llm"]  # Reasoning techniques (TEA-AGENT-001.4-rust): CoT, ReAct, self-correct, decompose
planning = []  # Planning primitives (TEA-AGENT-001.3-rust): decompose, execute, replan, status
a2a = ["dep:dashmap", "dep:bincode"]  # Inter-agent communication (TEA-AGENT-001.5-rust)
markdown = ["dep:md-parser"]  # Markdown parsing action (TEA-RALPHY-001.2)
game = []  # Game engine module (TEA-GAME-001.1)
game-duckdb = ["game", "dep:duckdb"]  # Game with DuckDB persistence (TEA-GAME-001.2, TEA-GAME-001.3)
prolog = ["dep:swipl"]
scryer = ["dep:scryer-prolog"]  # Pure Rust Prolog (TEA-RELEASE-005.1)
ltm-duckdb = ["dep:duckdb"]
graph = ["dep:cozo"]
llm-local = ["llm", "dep:llama-cpp-2"]  # Local LLM via llama.cpp (TEA-RELEASE-004.4) - dirs is now always available
llm-local-cuda = ["llm-local", "llama-cpp-2/cuda"]  # Local LLM with CUDA GPU support
llm-local-metal = ["llm-local", "llama-cpp-2/metal"]  # Local LLM with Metal GPU support (macOS)
llm-local-vulkan = ["llm-local", "llama-cpp-2/vulkan"]  # Local LLM with Vulkan GPU support
all = ["memory", "trace", "data", "web", "rag", "llm", "code", "agent", "reflection", "reasoning", "planning", "a2a", "prolog", "ltm-duckdb", "graph"]

[dependencies.duckdb]
version = "1.1"
optional = true

[dependencies.cozo]
version = "0.7"
optional = true

# Prolog support (SWI-Prolog bindings)
[dependencies.swipl]
version = "0.3"
optional = true

# Scryer Prolog - Pure Rust Prolog implementation (TEA-RELEASE-005.1)
[dependencies.scryer-prolog]
version = "0.10"
optional = true

# Local LLM via llama.cpp (TEA-RELEASE-004.4)
[dependencies.llama-cpp-2]
version = "0.1"
optional = true

# Home directory resolution for model path (no longer optional - used by report module)

[[bench]]
name = "graph_benchmarks"
harness = false

[[bench]]
name = "scryer_benchmarks"
harness = false
required-features = ["scryer"]

[profile.release]
lto = true
codegen-units = 1
strip = true
opt-level = "z"

[profile.release-with-debug]
inherits = "release"
debug = true
strip = false
