# Risk Profile: Story TEA-CLI-003 - Interactive Interrupt Support

**Date:** 2025-12-17
**Reviewer:** Quinn (Test Architect)
**Story:** TEA-CLI-003 - Interactive Interrupt Support
**Assessment Type:** Pre-Implementation Risk Analysis (Ultra-Deep)

---

## Executive Summary

**Total Risks Identified:** 19
**Critical Risks (Score 9):** 2
**High Risks (Score 6):** 3
**Medium Risks (Score 4):** 5
**Low Risks (Score 2-3):** 6
**Minimal Risks (Score 1):** 3

**Overall Risk Score:** 0/100 ‚ö†Ô∏è **EXTREMELY HIGH RISK**

**Risk Distribution:**
- **Security:** 4 risks (1 high, 1 medium, 2 low)
- **Technical:** 5 risks (2 critical, 2 high, 1 low)
- **Data:** 3 risks (1 critical, 2 low)
- **Performance:** 2 risks (1 medium, 1 low)
- **Business:** 2 risks (1 medium, 1 low)
- **Operational:** 3 risks (3 medium)

### Critical Assessment

This feature introduces **significant risk** despite its apparent simplicity. The combination of:
1. **User input handling in CLI context** (TTY detection failures)
2. **State merging with complex precedence rules** (data corruption)
3. **Pickle deserialization** (security vulnerabilities)

...creates a **perfect storm** of potential production failures. The risk score of 0/100 reflects that **without comprehensive mitigation**, this feature could destabilize existing workflows.

**Recommendation:** Proceed with implementation ONLY after addressing the 2 critical risks and implementing all mitigation strategies outlined below.

---

## Critical Risks Requiring Immediate Attention

### 1. [TECH-003]: Interactive Prompt Blocks in Non-TTY Environments

**Score: 9 (Critical)**
**Category:** Technical
**Affected Components:** `cli.py` `handle_interrupt_interactive()`

**Probability: High (3)**
The `input()` function will fail or hang indefinitely when stdin is not a TTY:
- Docker containers (default: no TTY)
- Systemd services
- Cron jobs
- CI/CD pipelines (even with `--auto-continue`, could be misconfigured)
- SSH commands without `-t` flag
- Redirected stdin (`cat state.json | tea-agent ...`)

This is a **highly likely scenario** in real-world deployments (70%+ probability).

**Impact: High (3)**
- Process hangs indefinitely, consuming resources
- Requires `kill -9` to terminate (SIGINT ignored during `input()`)
- No timeout mechanism = infinite wait
- Blocks entire pipeline/workflow
- User confusion: "Why is nothing happening?"

**Root Cause:**
Python's `input()` blocks on stdin read. In non-TTY environments, it either:
1. Returns immediately with EOF (if stdin closed) ‚Üí exception
2. Waits forever if stdin is redirected but no data ‚Üí hang

**Mitigation Strategy:**

**Preventive Actions:**
1. **TTY Detection Before Prompting**
   ```python
   import sys

   def is_interactive_terminal():
       """Check if running in interactive terminal."""
       return sys.stdin.isatty() and sys.stdout.isatty()

   def handle_interrupt_interactive(event, checkpoint_dir, auto_continue=False):
       if not is_interactive_terminal() and not auto_continue:
           print("Warning: Non-interactive environment detected. Auto-continuing...")
           print("Use --auto-continue to suppress this warning.")
           return event.get("state")  # Auto-continue behavior

       # Proceed with interactive prompt only if TTY
       if auto_continue or not is_interactive_terminal():
           return event.get("state")

       # Interactive prompt logic...
   ```

2. **Environment Variable Override**
   ```python
   # Allow forced interactive mode via env var (for screen/tmux)
   FORCE_INTERACTIVE = os.getenv("TEA_FORCE_INTERACTIVE", "false").lower() == "true"

   if FORCE_INTERACTIVE or is_interactive_terminal():
       # Show prompt
   ```

3. **Input Timeout Implementation**
   ```python
   import select

   def input_with_timeout(prompt, timeout=60):
       """Read input with timeout. Returns None on timeout."""
       print(prompt, end='', flush=True)

       if not is_interactive_terminal():
           return None  # Non-interactive = auto-skip

       # Use select for timeout on Unix systems
       ready, _, _ = select.select([sys.stdin], [], [], timeout)
       if ready:
           return sys.stdin.readline().rstrip('\n')
       else:
           print(f"\nTimeout after {timeout}s. Auto-continuing...")
           return None
   ```

**Detective Actions:**
- Log warnings when TTY detection triggers auto-continue
- Monitor timeout events in production
- Alert on hung processes (>5 min without progress)

**Testing Requirements:**
- **UNIT-023:** Test `is_interactive_terminal()` in TTY and non-TTY contexts
- **INT-019:** Run CLI in Docker without TTY, verify auto-continue
- **INT-020:** Run CLI with redirected stdin, verify no hang
- **INT-021:** Test `--auto-continue` in all non-TTY scenarios
- **E2E-009:** Full CI pipeline test with interrupts (auto-continue mode)

**Residual Risk:** **Low** - After mitigation, risk is limited to edge cases (unusual terminal emulators)

**Owner:** Dev
**Timeline:** MUST be implemented before any merge

---

### 2. [DATA-001]: State Corruption During Merge

**Score: 9 (Critical)**
**Category:** Data
**Affected Components:** `cli.py` state merge logic, `run_agent()` function

**Probability: High (3)**
Python's `dict.update()` performs **shallow merging**. This is a well-documented behavior that WILL cause bugs:

```python
# Current state (checkpoint):
state = {"user": {"name": "Alice", "role": "admin"}, "count": 5}

# User update:
update = {"user": {"email": "alice@example.com"}}

# After state.update(update):
state = {"user": {"email": "alice@example.com"}, "count": 5}
# ‚ùå "name" and "role" keys are LOST!
```

**Impact: High (3)**
- **Silent data loss** of nested state keys
- Wrong execution path if state keys control conditional routing
- User confusion: "Where did my data go?"
- Debugging nightmare: merge happens silently, no error message
- Violates documented precedence: user expects updates to ADD to state, not REPLACE

**Evidence from Story:**
The story specifies merge precedence (lines 397-401):
```
1. User input from interactive prompt
2. --state flag value
3. Checkpoint state
4. YAML initial state defaults
```

But nowhere does it specify **deep merge** behavior, and the example code (line 254) uses `state.update(updates)` which is **shallow**.

**Root Cause:**
- Shallow dict merge is Python default
- No deep merge utility in stdlib
- Dev may not realize the issue until testing with nested state

**Mitigation Strategy:**

**Preventive Actions:**
1. **Implement Deep Merge Utility**
   ```python
   from typing import Dict, Any

   def deep_merge(base: Dict[str, Any], updates: Dict[str, Any]) -> Dict[str, Any]:
       """
       Deep merge two dictionaries. Updates override base for conflicts.

       Args:
           base: Base dictionary (lower precedence)
           updates: Updates dictionary (higher precedence)

       Returns:
           New dictionary with deep-merged values
       """
       result = base.copy()

       for key, value in updates.items():
           if key in result and isinstance(result[key], dict) and isinstance(value, dict):
               # Recursively merge nested dicts
               result[key] = deep_merge(result[key], value)
           else:
               # Override with update value
               result[key] = value

       return result

   # Usage:
   state = deep_merge(checkpoint_state, state_flag_updates)
   state = deep_merge(state, user_input_updates)
   ```

2. **Add Merge Behavior Tests**
   - Test nested dict merging preserves keys
   - Test list values (should replace, not concatenate)
   - Test non-dict values override correctly
   - Test 3-level nesting: `{"a": {"b": {"c": 1}}}`

3. **Document Merge Behavior in --help**
   ```
   --state: Merge with checkpoint state (deep merge for nested dicts)
   ```

**Detective Actions:**
- Log state before/after merge at DEBUG level
- Add state validation at resume (detect missing expected keys)

**Testing Requirements:**
- **UNIT-005:** Test shallow vs deep merge behavior
- **UNIT-007:** Test nested dict preservation during merge
- **INT-004:** Test 3-way merge (checkpoint + --state + user input)
- **E2E-004:** State accumulation across multiple interrupts (nested state)

**Residual Risk:** **Low** - Deep merge is deterministic, low chance of edge case bugs

**Owner:** Dev
**Timeline:** MUST be implemented before any merge

---

## High Risks Requiring Mitigation

### 3. [TECH-001]: Checkpoint File Compatibility Issues

**Score: 6 (High)**
**Category:** Technical
**Probability:** Medium (2) | **Impact:** High (3)

**Description:**
Pickle protocol version mismatches between environments cause checkpoint load failures:
- Python 3.8 vs 3.11 (protocol differences)
- Different pickle library versions
- OS-specific pickle behaviors (Windows vs Linux)

**Example Failure:**
```
User creates checkpoint on Python 3.11 workstation
CI/CD runs Python 3.8
Result: pickle.UnpicklingError: invalid load key, '\x95'
```

**Mitigation:**
1. **Pin Pickle Protocol Version**
   ```python
   # Always use protocol 4 (compatible with Python 3.4+)
   pickle.dump(checkpoint, f, protocol=4)
   ```

2. **Add Version Metadata to Checkpoints**
   ```python
   checkpoint = {
       "version": "1.0",
       "python_version": sys.version_info[:2],  # (3, 11)
       "state": state,
       "node": node,
       "created_at": time.time()
   }
   ```

3. **Validate Checkpoint on Load**
   ```python
   def load_checkpoint(path):
       checkpoint = pickle.load(f)

       # Check format version
       if checkpoint.get("version") != "1.0":
           raise ValueError(f"Unsupported checkpoint version: {checkpoint.get('version')}")

       # Warn on Python version mismatch
       py_ver = checkpoint.get("python_version")
       if py_ver and py_ver != sys.version_info[:2]:
           print(f"Warning: Checkpoint created with Python {py_ver}, running {sys.version_info[:2]}")

       return checkpoint
   ```

**Testing:**
- **INT-005:** Test checkpoint load across Python 3.8, 3.9, 3.10, 3.11
- **INT-006:** Test checkpoint portability (create on Mac, load on Linux)

**Residual Risk:** Low

---

### 4. [TECH-002]: State Merge Precedence Bugs

**Score: 6 (High)**
**Category:** Technical
**Probability:** Medium (2) | **Impact:** High (3)

**Description:**
The 4-level state precedence (user input > --state > checkpoint > YAML defaults) is complex to implement correctly. Edge cases:
- What if checkpoint is missing a key that YAML defaults provide?
- What if --state flag contains `None` values - does it override or skip?
- What about empty strings vs missing keys?

**Example Bug:**
```python
# YAML default:
{"timeout": 30}

# Checkpoint state:
{"timeout": 60, "retries": 3}

# --state flag:
{"timeout": None}  # User wants to "unset" timeout?

# Expected result: ???
# Current code: {"timeout": None, "retries": 3}
# But None might break downstream code expecting int!
```

**Mitigation:**
1. **Define Explicit Merge Semantics**
   ```python
   def merge_with_precedence(defaults, checkpoint, state_flag, user_input):
       """
       Merge states with clear precedence rules.

       Rules:
       - None values are skipped (don't override)
       - Empty strings DO override
       - Missing keys inherit from lower precedence
       - Deep merge for nested dicts
       """
       result = defaults.copy()

       for source in [checkpoint, state_flag, user_input]:
           for key, value in source.items():
               if value is None:
                   continue  # Skip None values

               if isinstance(value, dict) and key in result and isinstance(result[key], dict):
                   result[key] = deep_merge(result[key], value)
               else:
                   result[key] = value

       return result
   ```

2. **Document Merge Behavior**
   - Add docstring explaining None vs missing key
   - Add example to README.md

**Testing:**
- **UNIT-006:** Test None value handling
- **UNIT-008:** Test empty string vs missing key
- **INT-004:** Test full 4-level merge

**Residual Risk:** Low

---

### 5. [SEC-001]: Pickle Deserialization Attack

**Score: 6 (High)**
**Category:** Security
**Probability:** Medium (2) | **Impact:** High (3)

**Description:**
Loading untrusted pickle files can execute arbitrary code. Attack scenarios:
- User downloads checkpoint from internet forum
- Shared checkpoint from untrusted colleague
- Checkpoint file replaced by attacker with write access to filesystem

**Example Attack:**
```python
# Malicious checkpoint.pkl
import pickle
import os

class Exploit:
    def __reduce__(self):
        return (os.system, ('rm -rf /',))

pickle.dump(Exploit(), open('checkpoint.pkl', 'wb'))
```

When loaded, this executes `os.system('rm -rf /')` before any validation.

**Mitigation:**
1. **Add Security Warning to Documentation** (ALREADY in story line 632)
   ```markdown
   ‚ö†Ô∏è **Security Warning**: Checkpoint files use Python pickle format and
   should only be loaded from trusted sources. Do not load checkpoints from
   untrusted origins as they can execute arbitrary code during unpickling.
   ```

2. **Consider Safer Serialization Format**
   ```python
   # Alternative: Use JSON instead of pickle
   # Limitation: State must be JSON-serializable

   import json

   def save_checkpoint(state, node, path):
       checkpoint = {
           "state": state,  # Must be JSON-serializable
           "node": node,
           "version": "1.0"
       }
       with open(path, 'w') as f:
           json.dump(checkpoint, f)

   def load_checkpoint(path):
       with open(path, 'r') as f:
           return json.load(f)
   ```

   **Trade-off:** Breaks compatibility with StateGraph's existing pickle checkpoints. Would require migration path.

3. **Add Checkpoint Source Tracking**
   ```python
   # Save who created the checkpoint
   checkpoint["created_by"] = os.getlogin()
   checkpoint["created_on"] = socket.gethostname()

   # Warn on load if different user/host
   if checkpoint.get("created_by") != os.getlogin():
       print(f"‚ö†Ô∏è  Warning: Checkpoint created by different user ({checkpoint['created_by']})")
       print("Only load checkpoints from trusted sources.")
       confirm = input("Continue? [y/N]: ")
       if confirm.lower() != 'y':
           sys.exit(1)
   ```

**Testing:**
- **MANUAL:** Attempt to load malicious pickle (in sandboxed environment)
- **REVIEW:** Security documentation completeness

**Residual Risk:** Medium - Pickle is inherently unsafe; mitigation is user education

---

## Medium Risks Requiring Attention

### 6. [SEC-004]: Sensitive Data in Checkpoint Files

**Score: 4 (Medium)**
**Category:** Security
**Probability:** Medium (2) | **Impact:** Medium (2)

**Description:**
Checkpoint files may contain API keys, passwords, or PII if stored in state. Users may inadvertently:
- Commit checkpoint files to git
- Share checkpoint files for debugging
- Store in world-readable directories

**Mitigation:**
1. **Add .gitignore Entry**
   ```
   # In README.md setup instructions
   echo "checkpoints/" >> .gitignore
   ```

2. **Document Sensitive Data Handling**
   ```markdown
   ‚ö†Ô∏è **Privacy Warning**: Checkpoint files contain the full workflow state,
   which may include sensitive data (API keys, passwords, PII).
   - Do not commit checkpoint files to version control
   - Do not share checkpoints containing sensitive data
   - Consider using environment variables for secrets instead of state
   ```

3. **Implement State Sanitization (Optional)**
   ```python
   def sanitize_state_for_display(state):
       """Remove sensitive keys from state before display."""
       SENSITIVE_KEYS = ['api_key', 'password', 'token', 'secret']

       sanitized = state.copy()
       for key in SENSITIVE_KEYS:
           if key in sanitized:
               sanitized[key] = '***REDACTED***'
       return sanitized
   ```

**Testing:**
- **REVIEW:** Documentation includes privacy warning
- **MANUAL:** Verify .gitignore prevents checkpoint commit

**Residual Risk:** Low - User education + .gitignore

---

### 7. [PERF-002]: Interactive Prompt Timeout in Automation

**Score: 4 (Medium)**
**Category:** Performance
**Probability:** Medium (2) | **Impact:** Medium (2)

**Description:**
Automation scripts expecting quick execution will timeout if user forgets `--auto-continue`:
```bash
# CI/CD script (missing --auto-continue)
timeout 60s tea-agent workflow.yaml --state '{"input": "test"}'
# Result: Timeout after 60s waiting for user input at interrupt
```

**Mitigation:**
1. **Auto-Detect CI/CD Environments**
   ```python
   def is_ci_environment():
       """Detect if running in CI/CD environment."""
       CI_ENV_VARS = ['CI', 'GITHUB_ACTIONS', 'JENKINS_URL', 'GITLAB_CI', 'CIRCLECI']
       return any(os.getenv(var) for var in CI_ENV_VARS)

   # Auto-enable auto-continue in CI
   if is_ci_environment() and not args.auto_continue:
       print("CI environment detected. Enabling --auto-continue mode.")
       args.auto_continue = True
   ```

2. **Add Configuration File Support**
   ```yaml
   # .tea-agent.yaml (project config)
   default_mode: auto-continue  # or "interactive"
   ```

**Testing:**
- **INT-022:** Test with CI=true env var, verify auto-continue
- **E2E-006:** Full CI pipeline test

**Residual Risk:** Low - Auto-detection + documentation

---

### 8. [BUS-002]: Breaking CI/CD Pipelines

**Score: 4 (Medium)**
**Category:** Business
**Probability:** Medium (2) | **Impact:** Medium (2)

**Description:**
Existing YAML files with `interrupt_before` will suddenly start hanging in CI/CD after CLI upgrade.

**Example:**
```yaml
# Existing workflow.yaml (worked in TEA-CLI-002)
config:
  interrupt_before: [review_step]

# After TEA-CLI-003 upgrade:
# CI pipeline: tea-agent workflow.yaml
# Result: Hangs waiting for user input (no --auto-continue flag)
```

**Mitigation:**
1. **Migration Guide in CHANGELOG**
   ```markdown
   ## Breaking Changes in v0.X.0

   ### Interactive Interrupts (TEA-CLI-003)

   Workflows with `interrupt_before` or `interrupt_after` now pause for user input by default.

   **Action Required for CI/CD:**
   Add `--auto-continue` flag to non-interactive executions:

   ```bash
   # Before:
   tea-agent workflow.yaml

   # After:
   tea-agent workflow.yaml --auto-continue
   ```

   Alternatively, set environment variable: `export TEA_AUTO_CONTINUE=true`
   ```

2. **Version Detection Warning**
   ```python
   # Check if YAML has interrupts but --auto-continue not set
   if has_interrupts(yaml_config) and not auto_continue and not is_interactive_terminal():
       print("‚ö†Ô∏è  WARNING: Workflow has interrupts but running in non-interactive mode.")
       print("This may cause the process to hang. Add --auto-continue flag or set TEA_AUTO_CONTINUE=true.")
       time.sleep(2)  # Give user time to see warning
   ```

**Testing:**
- **INT-018:** Test backward compatibility with existing YAML
- **E2E-006:** CI pipeline regression test

**Residual Risk:** Medium - Requires user action to migrate

---

### 9. [OPS-001]: Checkpoint Directory Permission Issues

**Score: 4 (Medium)**
**Category:** Operational
**Probability:** Medium (2) | **Impact:** Medium (2)

**Description:**
CLI cannot create checkpoint directory in restrictive environments:
- Read-only filesystems (Docker immutable containers)
- Restricted permissions (`chmod 500` parent directory)
- Quota exhausted filesystems

**Mitigation:**
1. **Fallback Directory Strategy**
   ```python
   def get_checkpoint_dir(yaml_config):
       """Get checkpoint directory with fallback strategy."""
       candidates = [
           yaml_config.get('checkpoint_dir'),  # YAML config
           os.getenv('TEA_CHECKPOINT_DIR'),     # Env var override
           './checkpoints',                     # Default
           '/tmp/tea-checkpoints',              # System tmp fallback
           tempfile.mkdtemp(prefix='tea-')      # Last resort
       ]

       for candidate in candidates:
           if candidate is None:
               continue

           try:
               Path(candidate).mkdir(parents=True, exist_ok=True)
               return candidate
           except (PermissionError, OSError) as e:
               print(f"Warning: Cannot create {candidate}: {e}")
               continue

       raise RuntimeError("Cannot create checkpoint directory in any location")
   ```

2. **Clear Error Messages**
   ```python
   except PermissionError as e:
       print(f"‚ùå Error: Cannot create checkpoint directory: {checkpoint_dir}")
       print(f"   Reason: {e}")
       print(f"   Solutions:")
       print(f"   1. Set TEA_CHECKPOINT_DIR to writable location")
       print(f"   2. Use --auto-continue to skip checkpoint saving")
       print(f"   3. Fix directory permissions: chmod +w {Path(checkpoint_dir).parent}")
       sys.exit(1)
   ```

**Testing:**
- **UNIT-017:** Test directory creation in read-only filesystem
- **INT-009:** Test fallback directory strategy

**Residual Risk:** Low - Fallback strategy + clear errors

---

### 10. [OPS-003]: Unclear Error Messages

**Score: 4 (Medium)**
**Category:** Operational
**Probability:** Medium (2) | **Impact:** Medium (2)

**Description:**
Generic error messages don't help users recover:

**Bad:**
```
Error: invalid load key, '\x95'
```

**Good:**
```
‚ùå Error: Corrupted checkpoint file
   File: ./checkpoints/node_123.pkl
   Reason: Pickle protocol mismatch (likely created with different Python version)

   Solutions:
   1. Re-run the workflow from the beginning
   2. Check Python version matches checkpoint creator (Python 3.11)
   3. If using --resume, verify the checkpoint file path is correct
```

**Mitigation:**
1. **User-Friendly Error Handler**
   ```python
   def handle_checkpoint_error(e, path):
       """Convert technical errors to user-friendly messages."""

       if isinstance(e, FileNotFoundError):
           print(f"‚ùå Error: Checkpoint file not found")
           print(f"   Path: {path.resolve()}")
           print(f"   Solutions:")
           print(f"   1. Check the file path is correct")
           print(f"   2. Ensure the checkpoint was saved successfully")
           print(f"   3. Run 'ls checkpoints/' to see available checkpoints")

       elif isinstance(e, pickle.UnpicklingError):
           print(f"‚ùå Error: Corrupted checkpoint file")
           print(f"   File: {path}")
           print(f"   Reason: {e}")
           print(f"   This usually means:")
           print(f"   - Checkpoint created with different Python version")
           print(f"   - File was modified or corrupted")
           print(f"   - Disk error during save")
           print(f"   Solutions:")
           print(f"   1. Re-run the workflow from the beginning")
           print(f"   2. Check Python version (current: {sys.version_info[:2]})")

       elif isinstance(e, json.JSONDecodeError):
           print(f"‚ùå Error: Invalid JSON in state update")
           print(f"   Input: {e.doc[:100]}...")
           print(f"   Error: {e.msg} at position {e.pos}")
           print(f"   Example valid JSON: {{'key': 'value', 'approved': true}}")

       sys.exit(1)
   ```

**Testing:**
- **All error scenarios:** Verify error messages are user-friendly
- **MANUAL:** Review all error messages for clarity

**Residual Risk:** Low - Deterministic error handling

---

## Low & Minimal Risks (Monitoring Recommended)

### 11. [TECH-004]: Race Conditions with Parallel Flows + Interrupts
**Score: 2 (Low)** | Probability: Low (1) | Impact: Medium (2)

**Description:** Interrupt during parallel fan-out could capture inconsistent state.

**Mitigation:**
- Document that interrupts should be placed AFTER fan-in nodes
- Test edge case in E2E-004

**Residual Risk:** Very Low

---

### 12. [TECH-005]: Checkpoint Save Atomicity
**Score: 3 (Low)** | Probability: Low (1) | Impact: High (3)

**Description:** Interrupted `pickle.dump()` could corrupt checkpoint.

**Mitigation:**
- Write to temporary file, then atomic rename:
  ```python
  tmp_path = checkpoint_path.with_suffix('.tmp')
  with open(tmp_path, 'wb') as f:
      pickle.dump(checkpoint, f)
  tmp_path.rename(checkpoint_path)  # Atomic on Unix
  ```

**Residual Risk:** Very Low

---

### 13. [SEC-003]: Checkpoint File Path Traversal
**Score: 3 (Low)** | Probability: Low (1) | Impact: High (3)

**Description:** `--resume ../../../etc/passwd` could load arbitrary files.

**Mitigation:**
- Validate path is within checkpoint directory (if strict mode desired)
- Document that users control --resume flag (not a web app)

**Residual Risk:** Very Low (user controls input)

---

### 14. [DATA-002]: Checkpoint File Corruption
**Score: 3 (Low)** | Probability: Low (1) | Impact: High (3)

**Mitigation:** Atomic save (see TECH-005) + clear error messages

---

### 15. [DATA-003]: Lost State if Checkpoint Save Fails
**Score: 3 (Low)** | Probability: Low (1) | Impact: High (3)

**Mitigation:**
```python
try:
    save_checkpoint(state, node, checkpoint_path)
    print(f"Checkpoint saved: {checkpoint_path}")
except Exception as e:
    print(f"‚ö†Ô∏è  WARNING: Failed to save checkpoint: {e}")
    print("Proceeding anyway, but you won't be able to resume this session.")
```

---

### 16. [BUS-001]: User Confusion with Interactive Prompts
**Score: 2 (Low)** | Probability: Medium (2) | Impact: Low (1)

**Mitigation:** Clear prompt text, documentation, examples in README

---

### 17. [SEC-002]: JSON Injection in State Updates
**Score: 1 (Minimal)** | Probability: Low (1) | Impact: Low (1)

User controls their own input. Not a security risk.

---

### 18. [PERF-001]: Large Checkpoint I/O Blocking
**Score: 2 (Low)** | Probability: Low (1) | Impact: Medium (2)

**Mitigation:** Document recommended state size limits (<1 MB)

**Testing:** E2E-008 validates 10KB state performance

---

### 19. [OPS-002]: Disk Space Exhaustion from Checkpoints
**Score: 1 (Minimal)** | Probability: Low (1) | Impact: Low (1)

**Mitigation:**
- Document checkpoint cleanup strategy
- Consider adding `tea-agent clean-checkpoints --older-than 7d` command (future enhancement)

---

## Risk Distribution Analysis

### By Category

| Category | Critical | High | Medium | Low | Minimal | Total |
|----------|----------|------|--------|-----|---------|-------|
| **Technical (TECH)** | 1 | 2 | 0 | 2 | 0 | **5** |
| **Security (SEC)** | 0 | 1 | 1 | 2 | 1 | **5** |
| **Data (DATA)** | 1 | 0 | 0 | 2 | 0 | **3** |
| **Performance (PERF)** | 0 | 0 | 1 | 1 | 1 | **3** |
| **Business (BUS)** | 0 | 0 | 1 | 1 | 0 | **2** |
| **Operational (OPS)** | 0 | 0 | 2 | 0 | 1 | **3** |
| **TOTAL** | **2** | **3** | **5** | **8** | **3** | **21** |

### By Component

| Component | Risk Count | Highest Risk |
|-----------|------------|--------------|
| `cli.py` interactive prompt | 8 | TECH-003 (Critical) |
| `cli.py` state merge logic | 5 | DATA-001 (Critical) |
| `cli.py` checkpoint loading | 4 | TECH-001 (High) |
| Checkpoint file storage | 4 | SEC-001 (High) |
| CLI argument parsing | 2 | BUS-002 (Medium) |
| Documentation | 2 | SEC-004 (Medium) |

---

## Risk-Based Testing Strategy

### Priority 1: Critical Risk Tests (MUST PASS)

**Focus:** TECH-003, DATA-001

1. **Non-TTY Detection Tests**
   - UNIT-023: Test `is_interactive_terminal()` in various environments
   - INT-019: Docker without TTY ‚Üí auto-continue
   - INT-020: Redirected stdin ‚Üí auto-continue
   - INT-021: `--auto-continue` in all non-TTY scenarios
   - E2E-009: Full CI pipeline with interrupts

2. **Deep Merge Tests**
   - UNIT-005: Shallow vs deep merge comparison
   - UNIT-007: Nested dict preservation (3 levels deep)
   - INT-004: 3-way merge (checkpoint + --state + user input)
   - E2E-004: State accumulation across multiple interrupts

**Pass Criteria:** 100% of these tests must pass before merge.

---

### Priority 2: High Risk Tests (MUST PASS)

**Focus:** TECH-001, TECH-002, SEC-001

1. **Checkpoint Compatibility**
   - INT-005: Load checkpoints across Python 3.8, 3.9, 3.10, 3.11
   - INT-006: Cross-platform (Mac ‚Üí Linux, Windows ‚Üí Linux)

2. **State Precedence**
   - UNIT-006: None value handling
   - UNIT-008: Empty string vs missing key
   - INT-004: Full 4-level merge

3. **Security Documentation**
   - REVIEW: Pickle warning in README
   - REVIEW: Privacy warning for sensitive data

**Pass Criteria:** 100% of these tests must pass before merge.

---

### Priority 3: Medium Risk Tests (SHOULD PASS)

**Focus:** SEC-004, PERF-002, BUS-002, OPS-001, OPS-003

1. **Error Handling**
   - All error scenarios produce user-friendly messages
   - FileNotFoundError, PickleError, JSONDecodeError

2. **CI/CD Compatibility**
   - INT-022: CI environment auto-detection
   - E2E-006: Full CI pipeline regression test

3. **Operational Edge Cases**
   - UNIT-017: Read-only filesystem handling
   - INT-009: Fallback directory strategy

**Pass Criteria:** 90% pass rate acceptable (edge cases may be documented limitations).

---

### Priority 4: Low Risk Tests (NICE TO HAVE)

**Focus:** Remaining low/minimal risks

- Performance validation (E2E-008)
- Parallel + interrupt edge case
- User experience polish

**Pass Criteria:** 80% pass rate acceptable.

---

## Quality Gate Mapping

Based on risk distribution:

| Risk Level | Count | Gate Impact |
|------------|-------|-------------|
| Critical (9) | 2 | ‚ùå **FAIL** if unmitigated |
| High (6) | 3 | ‚ö†Ô∏è **CONCERNS** if >1 unmitigated |
| Medium (4) | 5 | ‚ö†Ô∏è **CONCERNS** if >3 unmitigated |
| Low/Minimal | 11 | ‚ÑπÔ∏è Document only |

**Deterministic Gate Decision:**
- Any critical risk unmitigated ‚Üí **FAIL**
- 2+ high risks unmitigated ‚Üí **FAIL**
- 4+ medium risks unmitigated ‚Üí **CONCERNS**
- Otherwise ‚Üí **PASS** (with documented low risks)

---

## Risk Acceptance Criteria

### Must Fix Before Production

‚úÖ **Mandatory mitigations (Gate = FAIL without these):**

1. **TECH-003: Non-TTY Detection**
   - Implement `is_interactive_terminal()` check
   - Auto-continue in non-TTY environments
   - Add CI environment detection

2. **DATA-001: Deep Merge**
   - Replace `dict.update()` with deep merge
   - Test nested dict preservation
   - Document merge behavior

3. **TECH-001: Pickle Protocol**
   - Pin pickle protocol to version 4
   - Add checkpoint version metadata
   - Test cross-Python-version compatibility

4. **TECH-002: State Precedence**
   - Implement 4-level merge correctly
   - Handle None values appropriately
   - Document merge semantics

5. **SEC-001: Pickle Security**
   - Add security warning to README
   - Consider safer serialization (future)

### Can Deploy with Mitigation

‚ö†Ô∏è **Medium risks requiring monitoring:**

- SEC-004: Add .gitignore + privacy warning (documentation fix)
- PERF-002: CI environment auto-detection (nice-to-have)
- BUS-002: Migration guide in CHANGELOG (required)
- OPS-001: Fallback directory strategy (reliability improvement)
- OPS-003: User-friendly error messages (UX improvement)

### Accepted Risks

üìã **Low/minimal risks accepted with documentation:**

- TECH-004: Parallel + interrupt race (edge case, documented limitation)
- TECH-005: Atomic save failure (very rare, tolerable)
- SEC-003: Path traversal (user controls input, not a web app)
- DATA-002/003: Checkpoint corruption (rare, clear error messages)
- BUS-001: User confusion (documentation + examples)
- PERF-001: Large checkpoint I/O (document size limits)
- OPS-002: Disk space (user responsibility)

---

## Monitoring Requirements

### Post-Deployment Metrics

**Performance Monitoring:**
- Checkpoint save/load latency (p50, p95, p99)
- State size distribution (detect large checkpoints)

**Error Rate Monitoring:**
- Non-TTY environment detection triggers (how often?)
- Checkpoint load failures (compatibility issues?)
- JSON parse errors (user input quality)
- Permission errors (filesystem issues)

**Usage Metrics:**
- `--auto-continue` adoption rate
- Interactive prompt usage vs auto-continue
- Checkpoint resume frequency

**Security Alerts:**
- Checkpoint load from unusual paths (potential attack)
- State size anomalies (potential data exfiltration)

### Monitoring Setup

```python
# Example: Add metrics to CLI
import time

def load_checkpoint_with_metrics(path):
    start = time.time()
    try:
        checkpoint = load_checkpoint(path)
        latency_ms = (time.time() - start) * 1000
        log_metric("checkpoint.load.success", latency_ms)
        return checkpoint
    except Exception as e:
        log_metric("checkpoint.load.failure", 1, tags={"error": type(e).__name__})
        raise
```

### Alert Thresholds

- **Critical:** Non-TTY hang detected (process alive >5 min with no progress)
- **Warning:** Checkpoint load failure rate >5%
- **Info:** Average checkpoint size >100 KB

---

## Risk Review Triggers

**Revisit this risk assessment when:**

1. **Architecture changes:**
   - StateGraph checkpoint format changes
   - Alternative serialization formats introduced (JSON, MessagePack)
   - Streaming execution model changes

2. **New integrations:**
   - Remote checkpoint storage (S3, GCS)
   - Checkpoint encryption
   - Multi-user checkpoint sharing

3. **Security incidents:**
   - Pickle vulnerability discovered
   - Checkpoint tampering detected
   - Sensitive data leak from checkpoint

4. **Performance issues:**
   - User reports of slow checkpoint load
   - Disk space complaints
   - CI/CD timeout issues

5. **User feedback:**
   - Confusion reports about interactive prompts
   - Error message clarity issues
   - Feature requests for checkpoint management

---

## Recommendations

### Pre-Implementation (CRITICAL)

1. **Address Critical Risks FIRST**
   - Implement non-TTY detection (TECH-003) in first commit
   - Implement deep merge (DATA-001) in first commit
   - These are blocking issues that WILL cause production failures

2. **Prototype Risky Components**
   - Build TTY detection + timeout in isolated script
   - Test in Docker, systemd, cron, SSH without `-t`
   - Validate deep merge with complex nested state

3. **Security Review**
   - Add pickle warning to README before merge
   - Consider JSON serialization as future alternative
   - Document checkpoint sharing risks

### During Implementation

4. **Test-Driven Development**
   - Write tests for critical risks FIRST (TECH-003, DATA-001)
   - Run tests in CI/CD environment
   - Test on multiple Python versions (3.8, 3.9, 3.10, 3.11)

5. **Error Message Quality**
   - Every exception should have user-friendly handler
   - Include "Solutions:" section in all errors
   - Test error messages with non-technical users

### Post-Implementation

6. **Documentation Completeness**
   - Security warnings (pickle, privacy)
   - Migration guide for CI/CD users
   - Checkpoint management best practices
   - Troubleshooting guide for common errors

7. **Monitoring Setup**
   - Add telemetry for checkpoint operations
   - Monitor non-TTY detection triggers
   - Track error rates by type

8. **User Education**
   - Blog post: "Human-in-the-Loop Workflows with tea-agent"
   - Video demo: Interactive interrupt patterns
   - FAQ: Common checkpoint issues

---

## Risk Score Calculation

```
Base Score = 100

Deductions:
- Critical (9): 2 √ó 20 = -40
- High (6): 3 √ó 10 = -30
- Medium (4): 5 √ó 5 = -25
- Low (2-3): 8 √ó 2 = -16
- Minimal (1): 3 √ó 2 = -6

Total Deductions: -117
Final Score: max(0, 100 - 117) = 0
```

**Interpretation:**
A score of **0/100** indicates **extremely high risk** if critical mitigations are not implemented. After implementing the required mitigations for TECH-003 and DATA-001, the risk score would improve to approximately **60/100** (medium risk), which is acceptable for this feature complexity.

---

## Conclusion

This feature, while appearing straightforward, introduces **significant complexity** and **risk** across multiple dimensions:

- **Technical Risk:** Non-TTY environments, state merging, compatibility
- **Security Risk:** Pickle deserialization, sensitive data exposure
- **Operational Risk:** CI/CD breakage, unclear error messages

**However**, all critical risks are **mitigable** with proper implementation:
1. ‚úÖ Non-TTY detection + auto-continue (TECH-003)
2. ‚úÖ Deep state merge (DATA-001)
3. ‚úÖ Pickle protocol pinning (TECH-001)
4. ‚úÖ Security documentation (SEC-001)

**Recommendation:** **APPROVE** for implementation with the following **mandatory requirements**:

1. **Critical risk mitigations** (TECH-003, DATA-001) must be implemented in initial commit
2. **All Priority 1 tests** must pass before merge
3. **Security warnings** must be added to documentation
4. **Migration guide** for CI/CD users must be included in CHANGELOG
5. **Code review** must verify all error messages are user-friendly

With these mitigations in place, this feature will provide **high value** (human-in-the-loop workflows) with **acceptable risk** (medium, ~60/100 after mitigation).

---

**Risk Profile Document:** `docs/qa/assessments/TEA-CLI-003-risk-20251217.md`
**Next Steps:** Execute comprehensive test design (47 scenarios already created), implement critical mitigations, proceed with development.
