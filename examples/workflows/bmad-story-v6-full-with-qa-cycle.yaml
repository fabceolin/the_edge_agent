name: bmad-story-v6-full-qa-cycle
description: |
  BMad v6 Full QA Cycle - With Formal QA Gates using TEA module.

  REQUIREMENT: Install TEA module (Test Architect Enterprise)
  Command: npx bmad-method install → Select "Test Architect (TEA)"

  Complete flow with QA Gates:
  1. PREPARATION PHASE:
     - Resolve story path (story must already exist)

  2. PO VALIDATION PHASE (Story Conformance):
     - PO Validate Story Draft - comprehensive story validation
     - Anti-hallucination verification, template completeness
     - GO/NO-GO decision before TEA QA

  3. QA VALIDATION PHASE (TEA Module):
     - Test Design (TD) - risk assessment + test strategy
     - NFR Assessment (NR) - non-functional requirements
     - Requirements Tracing (TR) - traceability + gate decision
     - Final Validate Story (VS) - checklist

  4. CORRECTION LOOP (if validation failed, max 1 iteration):
     - Correct Course (CC)
     - Re-run validation from PO phase
     - If still fails → INTERRUPT

  5. DEVELOPMENT PHASE:
     - ATDD (AT) - generate acceptance tests (red phase)
     - Dev Story (DS) - implement (green phase)
     - Test Automation (TA) - expand coverage
     - Test Review (RV) - quality scoring
     - Code Review (CR) - adversarial review
     - Sprint Status (SS)

  Usage: tea run examples/workflows/bmad-story-v6-full-qa-cycle.yaml --input '{"arg": "epic-1-story-1"}'

state_schema:
  arg: str
  story_path: str
  story_key: str
  story_id: str
  # Skip validation check
  already_validated: bool
  current_status: str
  # TEA artifacts check
  tea_artifacts_exist: bool
  tea_test_design_path: str
  tea_nfr_path: str
  tea_trace_path: str
  # PO Validation phase
  po_validate_output: str
  po_validation_status: str
  po_readiness_score: int
  # QA Validation phase (TEA module)
  test_design_output: str
  risk_level: str
  nfr_output: str
  trace_output: str
  gate_decision: str
  validate_story_output: str
  validation_status: str
  # Correction loop tracking
  correction_attempt: int
  correct_course_output: str
  # Development phase
  atdd_output: str
  dev_output: str
  test_automation_output: str
  test_review_output: str
  quality_score: str
  review_output: str
  review_status: str
  review_fix_attempt: int
  sprint_status_output: str
  final_status: str

settings:
  shell_providers:
    claude:
      command: claude
      args: ["-p", "{prompt}", "--dangerously-skip-permissions"]
      verbose: true
      timeout: 108000

nodes:
  # ============================================================================
  # NODE 0: Resolve story path, check status, and check TEA artifacts
  # ============================================================================
  - name: resolve_story_path
    description: Convert story key to full story path, check if already validated, check TEA artifacts
    run: |
      import os
      import glob
      import yaml
      import re

      arg = state.get("arg", "")
      story_path = None
      story_key = None

      if os.path.isfile(arg):
          story_path = arg
          story_key = os.path.basename(arg).replace(".md", "")
      else:
          config_paths = ["_bmad/bmm/config.yaml", ".bmad/bmm/config.yaml"]
          impl_artifacts = "_bmad-output/implementation-artifacts"

          for config_path in config_paths:
              if os.path.exists(config_path):
                  try:
                      with open(config_path, 'r') as f:
                          config = yaml.safe_load(f)
                      impl_artifacts = config.get("implementation_artifacts", impl_artifacts)
                      break
                  except:
                      pass

          patterns = [
              os.path.join(impl_artifacts, f"{arg}.md"),
              os.path.join(impl_artifacts, f"*{arg}*.md"),
              f"**/{arg}.md"
          ]

          for pattern in patterns:
              matches = glob.glob(pattern, recursive=True)
              if matches:
                  story_path = matches[0]
                  story_key = os.path.basename(story_path).replace(".md", "")
                  break

          if not story_path:
              story_key = arg
              story_path = os.path.join(impl_artifacts, f"{arg}.md")

      # Extract story_id from story_key (e.g., "1-3-neo4j-connection" -> "1-3")
      story_id = story_key
      id_match = re.match(r'^(\d+-\d+)', story_key)
      if id_match:
          story_id = id_match.group(1)

      # Check if story is already in ready-for-dev, done, review, or in-progress status
      already_validated = False
      current_status = "unknown"
      if story_path and os.path.isfile(story_path):
          try:
              with open(story_path, 'r') as f:
                  content = f.read(500)  # Read first 500 chars for status
              status_match = re.search(r'^Status:\s*(\S+)', content, re.MULTILINE)
              if status_match:
                  current_status = status_match.group(1).lower()
                  if current_status in ['ready-for-dev', 'done', 'review', 'in-progress']:
                      already_validated = True
          except:
              pass

      # Check if TEA artifacts already exist
      tea_test_design_path = f"_bmad-output/test-artifacts/test-design/test-design-story-{story_id}.md"
      tea_nfr_path = f"_bmad-output/test-artifacts/nfr-assessments/nfr-assessment-story-{story_id}.md"
      tea_trace_path = f"_bmad-output/test-artifacts/traceability/trace-story-{story_id}.md"

      tea_artifacts_exist = (
          os.path.isfile(tea_test_design_path) and
          os.path.isfile(tea_nfr_path) and
          os.path.isfile(tea_trace_path)
      )

      if already_validated:
          print(f"""
      ╔════════════════════════════════════════════════════════════╗
      ║        STORY ALREADY VALIDATED - SKIPPING VALIDATION       ║
      ╠════════════════════════════════════════════════════════════╣
      ║ Story: {story_key:<52} ║
      ║ Status: {current_status:<51} ║
      ║ TEA Artifacts: {'EXIST' if tea_artifacts_exist else 'MISSING':<43} ║
      ╠════════════════════════════════════════════════════════════╣
      ║ Story is already in a validated state.                     ║
      ║ Skipping PO validation phase.                              ║
      {'║ TEA artifacts exist - skipping TEA QA phase.               ║' if tea_artifacts_exist else '║ TEA artifacts missing - will run TEA QA phase.             ║'}
      ╚════════════════════════════════════════════════════════════╝
          """)
      elif tea_artifacts_exist:
          print(f"""
      ╔════════════════════════════════════════════════════════════╗
      ║        TEA ARTIFACTS FOUND - WILL SKIP TEA PHASES          ║
      ╠════════════════════════════════════════════════════════════╣
      ║ Story: {story_key:<52} ║
      ║ Status: {current_status:<51} ║
      ╠════════════════════════════════════════════════════════════╣
      ║ TEA Test Design: ✓ EXISTS                                  ║
      ║ TEA NFR Assessment: ✓ EXISTS                               ║
      ║ TEA Traceability: ✓ EXISTS                                 ║
      ╠════════════════════════════════════════════════════════════╣
      ║ Will run PO validation, skip TEA phases.                   ║
      ╚════════════════════════════════════════════════════════════╝
          """)

      return {
          "story_path": story_path,
          "story_key": story_key,
          "story_id": story_id,
          "already_validated": already_validated,
          "current_status": current_status,
          "tea_artifacts_exist": tea_artifacts_exist,
          "tea_test_design_path": tea_test_design_path,
          "tea_nfr_path": tea_nfr_path,
          "tea_trace_path": tea_trace_path
      }

  # ============================================================================
  # PO VALIDATION PHASE (Story Conformance)
  # ============================================================================

  - name: po_validate_story_draft
    description: Validate story using create-story checklist
    uses: llm.call
    with:
      provider: shell
      shell_provider: claude
      timeout: 3600
      messages:
        - role: user
          content: |
            Validate this story using the create-story checklist:
            {{ state.story_path }}

            This will:
            1. Load the story file
            2. Load workflow.yaml for variable context
            3. Load source documents (epics, architecture, etc.)
            4. Run the systematic 5-step analysis from the checklist
            5. Present findings with critical/enhancement/optimization categories

            INSTRUCTIONS:
            1. Run the validation completely
            2. Review all findings
            3. If there are CRITICAL issues that block development, note them
            4. If no critical blockers, the story is ready

            After validation, determine readiness:
            - Count critical issues found
            - Assess overall implementation readiness (1-10 scale)

            At the end, print EXACTLY these lines:
            - If ready: PO_VALIDATION_GO
            - If not ready: PO_VALIDATION_NOGO
            - Always print: READINESS_SCORE:[1-10] (e.g., READINESS_SCORE:8)
            - Summary of critical issues if any
    output: po_validate_output

  - name: check_po_validation
    description: Parse PO validation output and determine if story is ready for TEA QA
    run: |
      import re

      output = state.get("po_validate_output", {})
      if isinstance(output, dict):
          text = output.get("content", "")
      else:
          text = str(output) if output else ""

      # Extract readiness score
      score_match = re.search(r'READINESS_SCORE:\s*(\d+)', text)
      if score_match:
          readiness_score = int(score_match.group(1))
      else:
          readiness_score = 5  # Default to middle score

      # Determine GO/NO-GO
      if "PO_VALIDATION_GO" in text:
          po_validation_status = "GO"
      elif "PO_VALIDATION_NOGO" in text or "NO-GO" in text.upper():
          po_validation_status = "NOGO"
      elif readiness_score >= 7:
          po_validation_status = "GO"
      else:
          po_validation_status = "NOGO"

      correction_attempt = state.get("correction_attempt", 0)

      print(f"""
      ╔════════════════════════════════════════════════════════════╗
      ║              PO VALIDATION PHASE COMPLETE                  ║
      ╠════════════════════════════════════════════════════════════╣
      ║ Story: {state.get('story_key', 'unknown'):<52} ║
      ╠════════════════════════════════════════════════════════════╣
      ║ Implementation Readiness Score: {readiness_score}/10                      ║
      ║ PO Validation Status: {po_validation_status:<37} ║
      ║ Correction Attempts: {correction_attempt:<38} ║
      ╚════════════════════════════════════════════════════════════╝
      """)

      if po_validation_status == "GO":
          print("\n✓ PO VALIDATION PASSED - Proceeding to TEA QA phase...")
      else:
          print("\n⚠️  PO VALIDATION FAILED - Story needs correction before TEA QA...")

      return {
          "po_validation_status": po_validation_status,
          "po_readiness_score": readiness_score
      }

  # ============================================================================
  # QA VALIDATION PHASE (TEA Module)
  # ============================================================================

  # NODE: TEA Test Design (TD) - Risk Assessment + Test Strategy
  - name: tea_test_design
    description: Execute TEA Test Design workflow with risk assessment
    uses: llm.call
    with:
      provider: shell
      shell_provider: claude
      timeout: 3600
      messages:
        - role: user
          content: |
            Execute TEA Test Design (TD) for story: {{ state.story_path }}

            Run command: bmad-tea-testarch-test-design

            The Test Design workflow will:
            1. Analyze story requirements
            2. Perform RISK ASSESSMENT (P0-P3 prioritization)
            3. Design test strategy based on risk level
            4. Create test scenarios matrix
            5. Output to test-design folder

            INSTRUCTIONS:
            1. Run the workflow completely
            2. Capture the RISK LEVEL (Critical/High/Medium/Low)
            3. Document test priorities

            After completion, append to story file {{ state.story_path }}:
            ## TEA - Test Design
            - Risk Level: [extracted risk level]
            - Test Strategy: [summary]
            - Priority Tests: [P0/P1 items]

            Print RISK_LEVEL:[Critical|High|Medium|Low] at the end
            Print: TEST_DESIGN_COMPLETED
    output: test_design_output

  # NODE: Extract risk level from test design output
  - name: extract_risk_level
    description: Parse risk level from test design output
    run: |
      import re

      output = state.get("test_design_output", {})
      if isinstance(output, dict):
          text = output.get("content", "")
      else:
          text = str(output) if output else ""

      # Extract risk level
      risk_match = re.search(r'RISK_LEVEL:\s*(Critical|High|Medium|Low)', text, re.IGNORECASE)
      if risk_match:
          risk_level = risk_match.group(1).upper()
      elif "critical" in text.lower():
          risk_level = "CRITICAL"
      elif "high" in text.lower() and "risk" in text.lower():
          risk_level = "HIGH"
      elif "medium" in text.lower():
          risk_level = "MEDIUM"
      else:
          risk_level = "LOW"

      print(f"Risk Level Detected: {risk_level}")
      return {"risk_level": risk_level}

  # NODE: TEA NFR Assessment (NR)
  - name: tea_nfr_assessment
    description: Execute TEA NFR Assessment workflow
    uses: llm.call
    with:
      provider: shell
      shell_provider: claude
      timeout: 3600
      messages:
        - role: user
          content: |
            Execute TEA NFR Assessment (NR) for story: {{ state.story_path }}

            Run command: bmad-tea-testarch-nfr

            The NFR Assessment workflow will:
            1. Evaluate non-functional requirements coverage
            2. Check performance requirements
            3. Check security requirements
            4. Check scalability requirements
            5. Check reliability requirements
            6. Identify gaps and recommendations

            INSTRUCTIONS:
            1. Run the workflow completely
            2. Document NFR coverage and gaps

            After completion, append to story file {{ state.story_path }}:
            ## TEA - NFR Assessment
            - Performance: [coverage status]
            - Security: [coverage status]
            - Scalability: [coverage status]
            - Gaps: [identified gaps]

            Print: NFR_ASSESSMENT_COMPLETED
    output: nfr_output

  # NODE: TEA Requirements Tracing (TR) - Gate Decision
  - name: tea_requirements_tracing
    description: Execute TEA Requirements Tracing with gate decision
    uses: llm.call
    with:
      provider: shell
      shell_provider: claude
      timeout: 3600
      messages:
        - role: user
          content: |
            Execute TEA Requirements Tracing (TR) for story: {{ state.story_path }}

            Run command: bmad-tea-testarch-trace

            The Requirements Tracing workflow will:
            1. Map all requirements to test coverage
            2. Create traceability matrix
            3. Identify coverage gaps
            4. Make RELEASE GATE DECISION

            INSTRUCTIONS:
            1. Run the workflow completely
            2. Capture the gate decision

            After completion, append to story file {{ state.story_path }}:
            ## TEA - Requirements Trace
            - Coverage: [percentage]
            - Gaps: [identified gaps]
            - Gate Decision: [PASS|CONDITIONAL|FAIL]

            Print GATE_DECISION:[PASS|CONDITIONAL|FAIL] at the end
            Print: TRACE_COMPLETED
    output: trace_output

  # NODE: Extract gate decision
  - name: extract_gate_decision
    description: Parse gate decision from trace output
    run: |
      import re

      output = state.get("trace_output", {})
      if isinstance(output, dict):
          text = output.get("content", "")
      else:
          text = str(output) if output else ""

      gate_match = re.search(r'GATE_DECISION:\s*(PASS|CONDITIONAL|FAIL)', text, re.IGNORECASE)
      if gate_match:
          gate_decision = gate_match.group(1).upper()
      elif "fail" in text.lower() and "gate" in text.lower():
          gate_decision = "FAIL"
      elif "conditional" in text.lower():
          gate_decision = "CONDITIONAL"
      else:
          gate_decision = "PASS"

      print(f"Gate Decision: {gate_decision}")
      return {"gate_decision": gate_decision}

  # NODE: Validate Story (VS) - Final checklist
  - name: validate_story
    description: Execute story validation checklist
    uses: llm.call
    with:
      provider: shell
      shell_provider: claude
      timeout: 3600
      messages:
        - role: user
          content: |
            Execute story validation for: {{ state.story_path }}

            Run command: bmad-bmm-create-story -v {{ state.story_path }}

            QA Gate Status from previous steps:
            - Risk Level: {{ state.risk_level }}
            - Gate Decision: {{ state.gate_decision }}

            VALIDATION CRITERIA:
            1. TEA Test Design section exists
            2. TEA NFR Assessment section exists
            3. TEA Requirements Trace section exists
            4. Gate Decision is PASS or CONDITIONAL
            5. Story meets Definition of Ready

            If gate_decision is FAIL, mark validation as FAILED.
            If all sections exist and gate is PASS/CONDITIONAL, mark as PASSED.

            Print: VALIDATION_PASSED or VALIDATION_FAILED
    output: validate_story_output

  # NODE: Check validation status
  - name: check_validation_status
    description: Determine if story passes QA gates
    run: |
      output = state.get("validate_story_output", {})
      if isinstance(output, dict):
          text = output.get("content", "")
      else:
          text = str(output) if output else ""

      gate_decision = state.get("gate_decision", "UNKNOWN")

      if gate_decision == "FAIL":
          validation_status = "FAILED_GATE"
      elif "VALIDATION_PASSED" in text:
          validation_status = "PASSED"
      elif "VALIDATION_FAILED" in text:
          validation_status = "FAILED"
      else:
          validation_status = "PASSED" if gate_decision in ["PASS", "CONDITIONAL"] else "FAILED"

      correction_attempt = state.get("correction_attempt", 0)

      print(f"""
      ╔════════════════════════════════════════════════════════════╗
      ║              QA VALIDATION PHASE COMPLETE                  ║
      ╠════════════════════════════════════════════════════════════╣
      ║ Story: {state.get('story_key', 'unknown'):<52} ║
      ╠════════════════════════════════════════════════════════════╣
      ║ TEA Test Design:      ✓ Completed                          ║
      ║ TEA NFR Assessment:   ✓ Completed                          ║
      ║ TEA Requirements Trace: ✓ Completed                        ║
      ╠════════════════════════════════════════════════════════════╣
      ║ Risk Level: {state.get('risk_level', 'UNKNOWN'):<47} ║
      ║ Gate Decision: {gate_decision:<44} ║
      ║ VALIDATION STATUS: {validation_status:<40} ║
      ╚════════════════════════════════════════════════════════════╝
      """)

      return {"validation_status": validation_status}

  # ============================================================================
  # CORRECTION LOOP
  # ============================================================================

  - name: correct_course
    description: Execute correct-course to fix validation failures
    uses: llm.call
    with:
      provider: shell
      shell_provider: claude
      timeout: 3600
      messages:
        - role: user
          content: |
            QA Validation FAILED. Execute course correction.

            Run command: bmad-bmm-correct-course

            Story: {{ state.story_path }}
            Gate Decision: {{ state.gate_decision }}
            Risk Level: {{ state.risk_level }}

            ISSUES TO ADDRESS:
            - Review TEA sections in story file
            - Fix requirements coverage gaps
            - Address NFR issues
            - Ensure gate criteria are met

            When done print: CORRECT_COURSE_COMPLETED
    output: correct_course_output

  - name: increment_correction_attempt
    description: Track correction iteration
    run: |
      current = state.get("correction_attempt", 0)
      new_attempt = current + 1

      print(f"""
      ╔════════════════════════════════════════════════════════════╗
      ║        CORRECTION COMPLETED (Attempt {new_attempt})                    ║
      ║ Re-running validation from PO phase...                     ║
      ╚════════════════════════════════════════════════════════════╝
      """)

      return {
          "correction_attempt": new_attempt,
          "po_validate_output": "",
          "po_validation_status": "",
          "po_readiness_score": 0,
          "test_design_output": "",
          "nfr_output": "",
          "trace_output": "",
          "gate_decision": "",
          "validation_status": ""
      }

  - name: validation_failed
    description: Handle validation failure after correction
    run: |
      print(f"""
      ╔════════════════════════════════════════════════════════════╗
      ║           QA GATE FAILED - INTERRUPTED                     ║
      ╠════════════════════════════════════════════════════════════╣
      ║ Story: {state.get('story_key', 'unknown'):<52} ║
      ║ Gate Decision: {state.get('gate_decision', 'FAIL'):<44} ║
      ║ Risk Level: {state.get('risk_level', 'UNKNOWN'):<47} ║
      ╠════════════════════════════════════════════════════════════╣
      ║  ⚠️  Story did not pass QA gates after correction.          ║
      ║  Manual intervention required.                             ║
      ╚════════════════════════════════════════════════════════════╝
      """)
      raise Exception(f"QA Gate FAILED for {state.get('story_key', 'unknown')}")

  # ============================================================================
  # DEVELOPMENT PHASE
  # ============================================================================

  # NODE: TEA ATDD (AT) - Generate acceptance tests (red phase)
  - name: tea_atdd
    description: Generate failing acceptance tests using TEA ATDD
    uses: llm.call
    with:
      provider: shell
      shell_provider: claude
      timeout: 3600
      messages:
        - role: user
          content: |
            Execute TEA ATDD (AT) for story: {{ state.story_path }}

            Run command: bmad-tea-testarch-atdd

            The ATDD workflow will:
            1. Generate acceptance tests based on story criteria
            2. Create failing tests (TDD red phase)
            3. Tests should fail until implementation is complete

            INSTRUCTIONS:
            1. Run the workflow completely
            2. Verify tests are created and currently failing

            Print: ATDD_COMPLETED
    output: atdd_output

  # NODE: Dev Story (DS)
  - name: dev_story
    description: Implement story (green phase)
    uses: llm.call
    with:
      provider: shell
      shell_provider: claude
      timeout: 7200
      messages:
        - role: user
          content: |
            Execute story development for: {{ state.story_path }}

            Run command: bmad-bmm-dev-story {{ state.story_path }}

            Risk Level: {{ state.risk_level }}

            INSTRUCTIONS:
            1. Implement all tasks sequentially
            2. Make acceptance tests PASS (green phase)
            3. Write unit tests for all functionality
            4. Update File List and Dev Agent Record

            When done print: DEV_STORY_COMPLETED
    output: dev_output

  # NODE: TEA Test Automation (TA)
  - name: tea_test_automation
    description: Expand test coverage using TEA
    uses: llm.call
    with:
      provider: shell
      shell_provider: claude
      timeout: 3600
      messages:
        - role: user
          content: |
            Execute TEA Test Automation (TA) for story: {{ state.story_path }}

            Run command: bmad-tea-testarch-automate

            Risk Level: {{ state.risk_level }}

            The Test Automation workflow will:
            1. Expand automation coverage based on risk
            2. Add edge case tests
            3. Add integration tests
            4. Ensure coverage meets gate requirements

            Print: TEST_AUTOMATION_COMPLETED
    output: test_automation_output

  # NODE: TEA Test Review (RV) - Quality Scoring
  - name: tea_test_review
    description: Execute TEA Test Review with quality scoring
    uses: llm.call
    with:
      provider: shell
      shell_provider: claude
      timeout: 3600
      messages:
        - role: user
          content: |
            Execute TEA Test Review (RV) for story: {{ state.story_path }}

            Run command: bmad-tea-testarch-test-review

            The Test Review workflow will:
            1. Evaluate test quality
            2. Calculate QUALITY SCORE
            3. Check coverage against requirements
            4. Provide improvement recommendations

            Append to story file:
            ## TEA - Test Review
            - Quality Score: [score]
            - Coverage: [percentage]
            - Recommendations: [list]

            Print QUALITY_SCORE:[0-100] at the end
            Print: TEST_REVIEW_COMPLETED
    output: test_review_output

  # NODE: Extract quality score
  - name: extract_quality_score
    description: Parse quality score from test review
    run: |
      import re

      output = state.get("test_review_output", {})
      if isinstance(output, dict):
          text = output.get("content", "")
      else:
          text = str(output) if output else ""

      score_match = re.search(r'QUALITY_SCORE:\s*(\d+)', text)
      if score_match:
          quality_score = score_match.group(1)
      else:
          quality_score = "N/A"

      print(f"Quality Score: {quality_score}")
      return {"quality_score": quality_score}

  # NODE: Code Review (CR)
  - name: code_review
    description: Adversarial code review
    uses: llm.call
    with:
      provider: shell
      shell_provider: claude
      timeout: 3600
      messages:
        - role: user
          content: |
            Execute code review for: {{ state.story_path }}

            Run command: bmad-bmm-code-review {{ state.story_path }}

            Quality Score from TEA: {{ state.quality_score }}
            Risk Level: {{ state.risk_level }}

            Review outcomes:
            - APPROVED: Print REVIEW_APPROVED
            - CHANGES_REQUESTED: Print REVIEW_CHANGES_REQUESTED
            - BLOCKED: Print REVIEW_BLOCKED
    output: review_output

  - name: check_review_status
    description: Parse review outcome
    run: |
      output = state.get("review_output", {})
      if isinstance(output, dict):
          text = output.get("content", "")
      else:
          text = str(output) if output else ""

      review_fix_attempt = state.get("review_fix_attempt", 0)

      if "REVIEW_APPROVED" in text or "Approve" in text:
          review_status = "APPROVED"
      elif "REVIEW_BLOCKED" in text:
          review_status = "BLOCKED"
      else:
          review_status = "CHANGES_REQUESTED"

      # Force exit after max attempts regardless of status
      if review_fix_attempt >= 2 and review_status != "APPROVED":
          print(f"Review Status: {review_status} (Max attempts {review_fix_attempt} reached - forcing exit)")
          review_status = "MAX_ATTEMPTS_REACHED"
      else:
          print(f"Review Status: {review_status} (Attempt: {review_fix_attempt}/2)")

      return {"review_status": review_status}

  - name: dev_fix_review
    description: Fix review issues
    uses: llm.call
    with:
      provider: shell
      shell_provider: claude
      timeout: 3600
      messages:
        - role: user
          content: |
            Fix code review issues for: {{ state.story_path }}

            Read Senior Developer Review section and address ALL issues.
            Run tests to confirm fixes.

            Print: DEV_FIXES_COMPLETED
    output: dev_output

  - name: increment_review_fix_attempt
    description: Track review fix iteration
    run: |
      current = state.get("review_fix_attempt", 0)
      new_attempt = current + 1
      print(f"Review Fix Attempt: {new_attempt} of 2")
      # Don't clear review_status here - let check_review_status handle it
      return {"review_fix_attempt": new_attempt, "review_output": ""}

  - name: sprint_status
    description: Update sprint status
    uses: llm.call
    with:
      provider: shell
      shell_provider: claude
      timeout: 600
      messages:
        - role: user
          content: |
            Update sprint status.
            Run command: bmad-bmm-sprint-status

            Story: {{ state.story_key }}
            Quality Score: {{ state.quality_score }}
            Review Status: {{ state.review_status }}

            Print: SPRINT_STATUS_UPDATED
    output: sprint_status_output

  # NODE: Final Summary
  - name: summary
    description: Generate final summary with QA metrics
    run: |
      story_key = state.get("story_key", "unknown")
      po_readiness_score = state.get("po_readiness_score", 0)
      po_validation_status = state.get("po_validation_status", "UNKNOWN")
      risk_level = state.get("risk_level", "UNKNOWN")
      gate_decision = state.get("gate_decision", "UNKNOWN")
      quality_score = state.get("quality_score", "N/A")
      review_status = state.get("review_status", "UNKNOWN")

      all_done = (
          state.get("validation_status") == "PASSED" and
          review_status == "APPROVED"
      )

      # Partial success if max attempts reached
      partial_success = (
          state.get("validation_status") == "PASSED" and
          review_status == "MAX_ATTEMPTS_REACHED"
      )

      print(f"""
      ╔════════════════════════════════════════════════════════════╗
      ║           BMad v6 Full QA Cycle Complete                   ║
      ╠════════════════════════════════════════════════════════════╣
      ║ Story: {story_key:<52} ║
      ╠════════════════════════════════════════════════════════════╣
      ║                    PO VALIDATION                           ║
      ╠════════════════════════════════════════════════════════════╣
      ║ PO Readiness Score: {po_readiness_score}/10                               ║
      ║ PO Validation: {po_validation_status:<44} ║
      ╠════════════════════════════════════════════════════════════╣
      ║                    QA METRICS                              ║
      ╠════════════════════════════════════════════════════════════╣
      ║ Risk Level: {risk_level:<47} ║
      ║ Gate Decision: {gate_decision:<44} ║
      ║ Quality Score: {quality_score:<44} ║
      ╠════════════════════════════════════════════════════════════╣
      ║                    WORKFLOW STATUS                         ║
      ╠════════════════════════════════════════════════════════════╣
      ║ PO Validate Story Draft: ✓                                 ║
      ║ TEA Test Design: ✓                                         ║
      ║ TEA NFR Assessment: ✓                                      ║
      ║ TEA Requirements Trace: ✓                                  ║
      ║ TEA ATDD: ✓                                                ║
      ║ Dev Story: ✓                                               ║
      ║ TEA Test Automation: ✓                                     ║
      ║ TEA Test Review: ✓                                         ║
      ║ Code Review: {review_status:<46} ║
      ╠════════════════════════════════════════════════════════════╣
      ║ FINAL RESULT: {'SUCCESS' if all_done else ('PARTIAL (max review attempts)' if partial_success else 'INCOMPLETE'):<45} ║
      ╚════════════════════════════════════════════════════════════╝
      """)

      final = "completed" if all_done else ("partial" if partial_success else "incomplete")
      return {"final_status": final}

edges:
  # PREPARATION
  - from: __start__
    to: resolve_story_path

  # Skip to development if story already validated AND TEA artifacts exist
  - from: resolve_story_path
    to: tea_atdd
    when: "state.get('already_validated', False) == True and state.get('tea_artifacts_exist', False) == True"

  # If already validated but no TEA artifacts, run TEA phases only
  - from: resolve_story_path
    to: tea_test_design
    when: "state.get('already_validated', False) == True and state.get('tea_artifacts_exist', False) != True"

  # Normal flow: proceed to PO validation if not already validated
  - from: resolve_story_path
    to: po_validate_story_draft
    when: "state.get('already_validated', False) != True"

  # PO VALIDATION ROUTING
  - from: po_validate_story_draft
    to: check_po_validation

  # If PO validation passed AND TEA artifacts exist, skip to development
  - from: check_po_validation
    to: tea_atdd
    when: "state.get('po_validation_status') == 'GO' and state.get('tea_artifacts_exist', False) == True"

  # If PO validation passed AND no TEA artifacts, run TEA phases
  - from: check_po_validation
    to: tea_test_design
    when: "state.get('po_validation_status') == 'GO' and state.get('tea_artifacts_exist', False) != True"

  - from: check_po_validation
    to: correct_course
    when: "state.get('po_validation_status') != 'GO' and state.get('correction_attempt', 0) == 0"

  - from: check_po_validation
    to: validation_failed
    when: "state.get('po_validation_status') != 'GO' and state.get('correction_attempt', 0) >= 1"

  # QA VALIDATION PHASE (TEA)
  - from: tea_test_design
    to: extract_risk_level
  - from: extract_risk_level
    to: tea_nfr_assessment
  - from: tea_nfr_assessment
    to: tea_requirements_tracing
  - from: tea_requirements_tracing
    to: extract_gate_decision
  - from: extract_gate_decision
    to: validate_story
  - from: validate_story
    to: check_validation_status

  # VALIDATION ROUTING
  - from: check_validation_status
    to: tea_atdd
    when: "state.get('validation_status') == 'PASSED'"

  - from: check_validation_status
    to: correct_course
    when: "state.get('validation_status') != 'PASSED' and state.get('correction_attempt', 0) == 0"

  - from: check_validation_status
    to: validation_failed
    when: "state.get('validation_status') != 'PASSED' and state.get('correction_attempt', 0) >= 1"

  # CORRECTION LOOP
  - from: correct_course
    to: increment_correction_attempt
  - from: increment_correction_attempt
    to: po_validate_story_draft
  - from: validation_failed
    to: __end__

  # DEVELOPMENT PHASE
  - from: tea_atdd
    to: dev_story
  - from: dev_story
    to: tea_test_automation
  - from: tea_test_automation
    to: tea_test_review
  - from: tea_test_review
    to: extract_quality_score
  - from: extract_quality_score
    to: code_review
  - from: code_review
    to: check_review_status

  # REVIEW ROUTING
  # Exit conditions (APPROVED or max attempts reached)
  - from: check_review_status
    to: sprint_status
    when: "state.get('review_status') in ['APPROVED', 'MAX_ATTEMPTS_REACHED', 'BLOCKED']"

  # Continue fixing only if CHANGES_REQUESTED (max attempts check is in check_review_status node)
  - from: check_review_status
    to: dev_fix_review
    when: "state.get('review_status') == 'CHANGES_REQUESTED'"

  - from: dev_fix_review
    to: increment_review_fix_attempt
  - from: increment_review_fix_attempt
    to: code_review

  # FINAL
  - from: sprint_status
    to: summary
  - from: summary
    to: __end__
