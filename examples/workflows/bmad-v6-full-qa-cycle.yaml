name: bmad-v6-full-qa-cycle
description: |
  BMad v6 Full QA Cycle - Com QA Gates Formais usando modulo TEA.

  REQUISITO: Instalar o modulo TEA (Test Architect Enterprise)
  Comando: npx bmad-method install → Selecionar "Test Architect (TEA)"

  Fluxo completo com QA Gates:
  1. FASE DE PREPARACAO:
     - Resolve story path
     - Create Story (CS)

  2. FASE DE VALIDACAO QA (TEA Module):
     - Test Design (TD) - risk assessment + test strategy
     - NFR Assessment (NR) - requisitos nao-funcionais
     - Requirements Tracing (TR) - rastreabilidade + gate decision
     - SM Validate Story (VS) - checklist final

  3. LOOP DE CORRECAO (se validacao falhou, max 1 iteracao):
     - Correct Course (CC)
     - Re-run validacao QA
     - Se ainda falha → INTERRUPT

  4. FASE DE DESENVOLVIMENTO:
     - ATDD (AT) - gera testes de aceitacao (red phase)
     - Dev Story (DS) - implementa (green phase)
     - Test Automation (TA) - expande cobertura
     - Test Review (RV) - quality scoring
     - Code Review (CR) - review adversarial
     - Sprint Status (SS)

  Usage: tea run examples/workflows/bmad-v6-full-qa-cycle.yaml --arg="epic-1-story-1"

state_schema:
  arg: str
  story_path: str
  story_key: str
  # QA Validation phase (TEA module)
  test_design_output: str
  risk_level: str
  nfr_output: str
  trace_output: str
  gate_decision: str
  validate_story_output: str
  validation_status: str
  # Correction loop tracking
  correction_attempt: int
  correct_course_output: str
  # Development phase
  atdd_output: str
  dev_output: str
  test_automation_output: str
  test_review_output: str
  quality_score: str
  review_output: str
  review_status: str
  review_fix_attempt: int
  sprint_status_output: str
  final_status: str

settings:
  shell_providers:
    claude:
      command: claude
      args: ["-p", "{prompt}", "--dangerously-skip-permissions"]
      verbose: true
      timeout: 108000

nodes:
  # ============================================================================
  # NODE 0: Resolve story path
  # ============================================================================
  - name: resolve_story_path
    description: Convert story key to full story path
    run: |
      import os
      import glob
      import yaml

      arg = state.get("arg", "")

      if os.path.isfile(arg):
          story_key = os.path.basename(arg).replace(".md", "")
          return {"story_path": arg, "story_key": story_key}

      config_paths = ["_bmad/bmm/config.yaml", ".bmad/bmm/config.yaml"]
      impl_artifacts = "_bmad-output/implementation-artifacts"

      for config_path in config_paths:
          if os.path.exists(config_path):
              try:
                  with open(config_path, 'r') as f:
                      config = yaml.safe_load(f)
                  impl_artifacts = config.get("implementation_artifacts", impl_artifacts)
                  break
              except:
                  pass

      patterns = [
          os.path.join(impl_artifacts, f"{arg}.md"),
          os.path.join(impl_artifacts, f"*{arg}*.md"),
          f"**/{arg}.md"
      ]

      for pattern in patterns:
          matches = glob.glob(pattern, recursive=True)
          if matches:
              story_path = matches[0]
              story_key = os.path.basename(story_path).replace(".md", "")
              return {"story_path": story_path, "story_key": story_key}

      story_key = arg
      story_path = os.path.join(impl_artifacts, f"{arg}.md")
      return {"story_path": story_path, "story_key": story_key}

  # ============================================================================
  # PREPARATION PHASE
  # ============================================================================

  - name: create_story
    description: Create story if needed using bmad-bmm-create-story
    uses: llm.call
    with:
      provider: shell
      shell_provider: claude
      timeout: 3600
      messages:
        - role: user
          content: |
            Check if story file exists at: {{ state.story_path }}

            If EXISTS with content: Print STORY_EXISTS_SKIPPING_CREATION
            If NOT exists or empty: Run bmad-bmm-create-story for {{ state.story_key }}

            When done with creation print: STORY_CREATED
    output: create_story_output

  # ============================================================================
  # QA VALIDATION PHASE (TEA Module)
  # ============================================================================

  # NODE: TEA Test Design (TD) - Risk Assessment + Test Strategy
  - name: tea_test_design
    description: Execute TEA Test Design workflow with risk assessment
    uses: llm.call
    with:
      provider: shell
      shell_provider: claude
      timeout: 3600
      messages:
        - role: user
          content: |
            Execute TEA Test Design (TD) for story: {{ state.story_path }}

            Run command: bmad-tea-test-design

            The Test Design workflow will:
            1. Analyze story requirements
            2. Perform RISK ASSESSMENT (P0-P3 prioritization)
            3. Design test strategy based on risk level
            4. Create test scenarios matrix
            5. Output to test-design folder

            INSTRUCTIONS:
            1. Run the workflow completely
            2. Capture the RISK LEVEL (Critical/High/Medium/Low)
            3. Document test priorities

            After completion, append to story file {{ state.story_path }}:
            ## TEA - Test Design
            - Risk Level: [extracted risk level]
            - Test Strategy: [summary]
            - Priority Tests: [P0/P1 items]

            Print RISK_LEVEL:[Critical|High|Medium|Low] at the end
            Print: TEST_DESIGN_COMPLETED
    output: test_design_output

  # NODE: Extract risk level from test design output
  - name: extract_risk_level
    description: Parse risk level from test design output
    run: |
      import re

      output = state.get("test_design_output", {})
      if isinstance(output, dict):
          text = output.get("content", "")
      else:
          text = str(output) if output else ""

      # Extract risk level
      risk_match = re.search(r'RISK_LEVEL:\s*(Critical|High|Medium|Low)', text, re.IGNORECASE)
      if risk_match:
          risk_level = risk_match.group(1).upper()
      elif "critical" in text.lower():
          risk_level = "CRITICAL"
      elif "high" in text.lower() and "risk" in text.lower():
          risk_level = "HIGH"
      elif "medium" in text.lower():
          risk_level = "MEDIUM"
      else:
          risk_level = "LOW"

      print(f"Risk Level Detected: {risk_level}")
      return {"risk_level": risk_level}

  # NODE: TEA NFR Assessment (NR)
  - name: tea_nfr_assessment
    description: Execute TEA NFR Assessment workflow
    uses: llm.call
    with:
      provider: shell
      shell_provider: claude
      timeout: 3600
      messages:
        - role: user
          content: |
            Execute TEA NFR Assessment (NR) for story: {{ state.story_path }}

            Run command: bmad-tea-nfr

            The NFR Assessment workflow will:
            1. Evaluate non-functional requirements coverage
            2. Check performance requirements
            3. Check security requirements
            4. Check scalability requirements
            5. Check reliability requirements
            6. Identify gaps and recommendations

            INSTRUCTIONS:
            1. Run the workflow completely
            2. Document NFR coverage and gaps

            After completion, append to story file {{ state.story_path }}:
            ## TEA - NFR Assessment
            - Performance: [coverage status]
            - Security: [coverage status]
            - Scalability: [coverage status]
            - Gaps: [identified gaps]

            Print: NFR_ASSESSMENT_COMPLETED
    output: nfr_output

  # NODE: TEA Requirements Tracing (TR) - Gate Decision
  - name: tea_requirements_tracing
    description: Execute TEA Requirements Tracing with gate decision
    uses: llm.call
    with:
      provider: shell
      shell_provider: claude
      timeout: 3600
      messages:
        - role: user
          content: |
            Execute TEA Requirements Tracing (TR) for story: {{ state.story_path }}

            Run command: bmad-tea-trace

            The Requirements Tracing workflow will:
            1. Map all requirements to test coverage
            2. Create traceability matrix
            3. Identify coverage gaps
            4. Make RELEASE GATE DECISION

            INSTRUCTIONS:
            1. Run the workflow completely
            2. Capture the gate decision

            After completion, append to story file {{ state.story_path }}:
            ## TEA - Requirements Trace
            - Coverage: [percentage]
            - Gaps: [identified gaps]
            - Gate Decision: [PASS|CONDITIONAL|FAIL]

            Print GATE_DECISION:[PASS|CONDITIONAL|FAIL] at the end
            Print: TRACE_COMPLETED
    output: trace_output

  # NODE: Extract gate decision
  - name: extract_gate_decision
    description: Parse gate decision from trace output
    run: |
      import re

      output = state.get("trace_output", {})
      if isinstance(output, dict):
          text = output.get("content", "")
      else:
          text = str(output) if output else ""

      gate_match = re.search(r'GATE_DECISION:\s*(PASS|CONDITIONAL|FAIL)', text, re.IGNORECASE)
      if gate_match:
          gate_decision = gate_match.group(1).upper()
      elif "fail" in text.lower() and "gate" in text.lower():
          gate_decision = "FAIL"
      elif "conditional" in text.lower():
          gate_decision = "CONDITIONAL"
      else:
          gate_decision = "PASS"

      print(f"Gate Decision: {gate_decision}")
      return {"gate_decision": gate_decision}

  # NODE: Validate Story (VS) - Final checklist
  - name: validate_story
    description: Execute story validation checklist
    uses: llm.call
    with:
      provider: shell
      shell_provider: claude
      timeout: 3600
      messages:
        - role: user
          content: |
            Execute story validation for: {{ state.story_path }}

            Run command: bmad-bmm-create-story -v {{ state.story_path }}

            QA Gate Status from previous steps:
            - Risk Level: {{ state.risk_level }}
            - Gate Decision: {{ state.gate_decision }}

            VALIDATION CRITERIA:
            1. TEA Test Design section exists
            2. TEA NFR Assessment section exists
            3. TEA Requirements Trace section exists
            4. Gate Decision is PASS or CONDITIONAL
            5. Story meets Definition of Ready

            If gate_decision is FAIL, mark validation as FAILED.
            If all sections exist and gate is PASS/CONDITIONAL, mark as PASSED.

            Print: VALIDATION_PASSED or VALIDATION_FAILED
    output: validate_story_output

  # NODE: Check validation status
  - name: check_validation_status
    description: Determine if story passes QA gates
    run: |
      output = state.get("validate_story_output", {})
      if isinstance(output, dict):
          text = output.get("content", "")
      else:
          text = str(output) if output else ""

      gate_decision = state.get("gate_decision", "UNKNOWN")

      if gate_decision == "FAIL":
          validation_status = "FAILED_GATE"
      elif "VALIDATION_PASSED" in text:
          validation_status = "PASSED"
      elif "VALIDATION_FAILED" in text:
          validation_status = "FAILED"
      else:
          validation_status = "PASSED" if gate_decision in ["PASS", "CONDITIONAL"] else "FAILED"

      correction_attempt = state.get("correction_attempt", 0)

      print(f"""
      ╔════════════════════════════════════════════════════════════╗
      ║              QA VALIDATION PHASE COMPLETE                  ║
      ╠════════════════════════════════════════════════════════════╣
      ║ Story: {state.get('story_key', 'unknown'):<52} ║
      ╠════════════════════════════════════════════════════════════╣
      ║ TEA Test Design:      ✓ Completed                          ║
      ║ TEA NFR Assessment:   ✓ Completed                          ║
      ║ TEA Requirements Trace: ✓ Completed                        ║
      ╠════════════════════════════════════════════════════════════╣
      ║ Risk Level: {state.get('risk_level', 'UNKNOWN'):<47} ║
      ║ Gate Decision: {gate_decision:<44} ║
      ║ VALIDATION STATUS: {validation_status:<40} ║
      ╚════════════════════════════════════════════════════════════╝
      """)

      return {"validation_status": validation_status}

  # ============================================================================
  # CORRECTION LOOP
  # ============================================================================

  - name: correct_course
    description: Execute correct-course to fix validation failures
    uses: llm.call
    with:
      provider: shell
      shell_provider: claude
      timeout: 3600
      messages:
        - role: user
          content: |
            QA Validation FAILED. Execute course correction.

            Run command: bmad-bmm-correct-course

            Story: {{ state.story_path }}
            Gate Decision: {{ state.gate_decision }}
            Risk Level: {{ state.risk_level }}

            ISSUES TO ADDRESS:
            - Review TEA sections in story file
            - Fix requirements coverage gaps
            - Address NFR issues
            - Ensure gate criteria are met

            When done print: CORRECT_COURSE_COMPLETED
    output: correct_course_output

  - name: increment_correction_attempt
    description: Track correction iteration
    run: |
      current = state.get("correction_attempt", 0)
      new_attempt = current + 1

      print(f"""
      ╔════════════════════════════════════════════════════════════╗
      ║        CORRECTION COMPLETED (Attempt {new_attempt})                    ║
      ║ Re-running QA validation phase...                          ║
      ╚════════════════════════════════════════════════════════════╝
      """)

      return {
          "correction_attempt": new_attempt,
          "test_design_output": "",
          "nfr_output": "",
          "trace_output": "",
          "gate_decision": "",
          "validation_status": ""
      }

  - name: validation_failed
    description: Handle validation failure after correction
    run: |
      print(f"""
      ╔════════════════════════════════════════════════════════════╗
      ║           QA GATE FAILED - INTERRUPTED                     ║
      ╠════════════════════════════════════════════════════════════╣
      ║ Story: {state.get('story_key', 'unknown'):<52} ║
      ║ Gate Decision: {state.get('gate_decision', 'FAIL'):<44} ║
      ║ Risk Level: {state.get('risk_level', 'UNKNOWN'):<47} ║
      ╠════════════════════════════════════════════════════════════╣
      ║  ⚠️  Story did not pass QA gates after correction.          ║
      ║  Manual intervention required.                             ║
      ╚════════════════════════════════════════════════════════════╝
      """)
      raise Exception(f"QA Gate FAILED for {state.get('story_key', 'unknown')}")

  # ============================================================================
  # DEVELOPMENT PHASE
  # ============================================================================

  # NODE: TEA ATDD (AT) - Generate acceptance tests (red phase)
  - name: tea_atdd
    description: Generate failing acceptance tests using TEA ATDD
    uses: llm.call
    with:
      provider: shell
      shell_provider: claude
      timeout: 3600
      messages:
        - role: user
          content: |
            Execute TEA ATDD (AT) for story: {{ state.story_path }}

            Run command: bmad-tea-atdd

            The ATDD workflow will:
            1. Generate acceptance tests based on story criteria
            2. Create failing tests (TDD red phase)
            3. Tests should fail until implementation is complete

            INSTRUCTIONS:
            1. Run the workflow completely
            2. Verify tests are created and currently failing

            Print: ATDD_COMPLETED
    output: atdd_output

  # NODE: Dev Story (DS)
  - name: dev_story
    description: Implement story (green phase)
    uses: llm.call
    with:
      provider: shell
      shell_provider: claude
      timeout: 7200
      messages:
        - role: user
          content: |
            Execute story development for: {{ state.story_path }}

            Run command: bmad-bmm-dev-story {{ state.story_path }}

            Risk Level: {{ state.risk_level }}

            INSTRUCTIONS:
            1. Implement all tasks sequentially
            2. Make acceptance tests PASS (green phase)
            3. Write unit tests for all functionality
            4. Update File List and Dev Agent Record

            When done print: DEV_STORY_COMPLETED
    output: dev_output

  # NODE: TEA Test Automation (TA)
  - name: tea_test_automation
    description: Expand test coverage using TEA
    uses: llm.call
    with:
      provider: shell
      shell_provider: claude
      timeout: 3600
      messages:
        - role: user
          content: |
            Execute TEA Test Automation (TA) for story: {{ state.story_path }}

            Run command: bmad-tea-automate

            Risk Level: {{ state.risk_level }}

            The Test Automation workflow will:
            1. Expand automation coverage based on risk
            2. Add edge case tests
            3. Add integration tests
            4. Ensure coverage meets gate requirements

            Print: TEST_AUTOMATION_COMPLETED
    output: test_automation_output

  # NODE: TEA Test Review (RV) - Quality Scoring
  - name: tea_test_review
    description: Execute TEA Test Review with quality scoring
    uses: llm.call
    with:
      provider: shell
      shell_provider: claude
      timeout: 3600
      messages:
        - role: user
          content: |
            Execute TEA Test Review (RV) for story: {{ state.story_path }}

            Run command: bmad-tea-review

            The Test Review workflow will:
            1. Evaluate test quality
            2. Calculate QUALITY SCORE
            3. Check coverage against requirements
            4. Provide improvement recommendations

            Append to story file:
            ## TEA - Test Review
            - Quality Score: [score]
            - Coverage: [percentage]
            - Recommendations: [list]

            Print QUALITY_SCORE:[0-100] at the end
            Print: TEST_REVIEW_COMPLETED
    output: test_review_output

  # NODE: Extract quality score
  - name: extract_quality_score
    description: Parse quality score from test review
    run: |
      import re

      output = state.get("test_review_output", {})
      if isinstance(output, dict):
          text = output.get("content", "")
      else:
          text = str(output) if output else ""

      score_match = re.search(r'QUALITY_SCORE:\s*(\d+)', text)
      if score_match:
          quality_score = score_match.group(1)
      else:
          quality_score = "N/A"

      print(f"Quality Score: {quality_score}")
      return {"quality_score": quality_score}

  # NODE: Code Review (CR)
  - name: code_review
    description: Adversarial code review
    uses: llm.call
    with:
      provider: shell
      shell_provider: claude
      timeout: 3600
      messages:
        - role: user
          content: |
            Execute code review for: {{ state.story_path }}

            Run command: bmad-bmm-code-review {{ state.story_path }}

            Quality Score from TEA: {{ state.quality_score }}
            Risk Level: {{ state.risk_level }}

            Review outcomes:
            - APPROVED: Print REVIEW_APPROVED
            - CHANGES_REQUESTED: Print REVIEW_CHANGES_REQUESTED
            - BLOCKED: Print REVIEW_BLOCKED
    output: review_output

  - name: check_review_status
    description: Parse review outcome
    run: |
      output = state.get("review_output", {})
      if isinstance(output, dict):
          text = output.get("content", "")
      else:
          text = str(output) if output else ""

      if "REVIEW_APPROVED" in text or "Approve" in text:
          review_status = "APPROVED"
      elif "REVIEW_BLOCKED" in text:
          review_status = "BLOCKED"
      else:
          review_status = "CHANGES_REQUESTED"

      print(f"Review Status: {review_status}")
      return {"review_status": review_status}

  - name: dev_fix_review
    description: Fix review issues
    uses: llm.call
    with:
      provider: shell
      shell_provider: claude
      timeout: 3600
      messages:
        - role: user
          content: |
            Fix code review issues for: {{ state.story_path }}

            Read Senior Developer Review section and address ALL issues.
            Run tests to confirm fixes.

            Print: DEV_FIXES_COMPLETED
    output: dev_output

  - name: increment_review_fix_attempt
    description: Track review fix iteration
    run: |
      current = state.get("review_fix_attempt", 0)
      return {"review_fix_attempt": current + 1, "review_output": "", "review_status": ""}

  - name: sprint_status
    description: Update sprint status
    uses: llm.call
    with:
      provider: shell
      shell_provider: claude
      timeout: 600
      messages:
        - role: user
          content: |
            Update sprint status.
            Run command: bmad-bmm-sprint-status

            Story: {{ state.story_key }}
            Quality Score: {{ state.quality_score }}
            Review Status: {{ state.review_status }}

            Print: SPRINT_STATUS_UPDATED
    output: sprint_status_output

  # NODE: Final Summary
  - name: summary
    description: Generate final summary with QA metrics
    run: |
      story_key = state.get("story_key", "unknown")
      risk_level = state.get("risk_level", "UNKNOWN")
      gate_decision = state.get("gate_decision", "UNKNOWN")
      quality_score = state.get("quality_score", "N/A")
      review_status = state.get("review_status", "UNKNOWN")

      all_done = (
          state.get("validation_status") == "PASSED" and
          review_status == "APPROVED"
      )

      print(f"""
      ╔════════════════════════════════════════════════════════════╗
      ║           BMad v6 Full QA Cycle Complete                   ║
      ╠════════════════════════════════════════════════════════════╣
      ║ Story: {story_key:<52} ║
      ╠════════════════════════════════════════════════════════════╣
      ║                    QA METRICS                              ║
      ╠════════════════════════════════════════════════════════════╣
      ║ Risk Level: {risk_level:<47} ║
      ║ Gate Decision: {gate_decision:<44} ║
      ║ Quality Score: {quality_score:<44} ║
      ╠════════════════════════════════════════════════════════════╣
      ║                    WORKFLOW STATUS                         ║
      ╠════════════════════════════════════════════════════════════╣
      ║ TEA Test Design: ✓                                         ║
      ║ TEA NFR Assessment: ✓                                      ║
      ║ TEA Requirements Trace: ✓                                  ║
      ║ TEA ATDD: ✓                                                ║
      ║ Dev Story: ✓                                               ║
      ║ TEA Test Automation: ✓                                     ║
      ║ TEA Test Review: ✓                                         ║
      ║ Code Review: {review_status:<46} ║
      ╠════════════════════════════════════════════════════════════╣
      ║ FINAL RESULT: {'SUCCESS' if all_done else 'INCOMPLETE':<45} ║
      ╚════════════════════════════════════════════════════════════╝
      """)

      return {"final_status": "completed" if all_done else "incomplete"}

edges:
  # PREPARATION
  - from: __start__
    to: resolve_story_path
  - from: resolve_story_path
    to: create_story
  - from: create_story
    to: tea_test_design

  # QA VALIDATION PHASE (TEA)
  - from: tea_test_design
    to: extract_risk_level
  - from: extract_risk_level
    to: tea_nfr_assessment
  - from: tea_nfr_assessment
    to: tea_requirements_tracing
  - from: tea_requirements_tracing
    to: extract_gate_decision
  - from: extract_gate_decision
    to: validate_story
  - from: validate_story
    to: check_validation_status

  # VALIDATION ROUTING
  - from: check_validation_status
    to: tea_atdd
    when: "state.get('validation_status') == 'PASSED'"

  - from: check_validation_status
    to: correct_course
    when: "state.get('validation_status') != 'PASSED' and state.get('correction_attempt', 0) == 0"

  - from: check_validation_status
    to: validation_failed
    when: "state.get('validation_status') != 'PASSED' and state.get('correction_attempt', 0) >= 1"

  # CORRECTION LOOP
  - from: correct_course
    to: increment_correction_attempt
  - from: increment_correction_attempt
    to: tea_test_design
  - from: validation_failed
    to: __end__

  # DEVELOPMENT PHASE
  - from: tea_atdd
    to: dev_story
  - from: dev_story
    to: tea_test_automation
  - from: tea_test_automation
    to: tea_test_review
  - from: tea_test_review
    to: extract_quality_score
  - from: extract_quality_score
    to: code_review
  - from: code_review
    to: check_review_status

  # REVIEW ROUTING
  - from: check_review_status
    to: sprint_status
    when: "state.get('review_status') == 'APPROVED'"

  - from: check_review_status
    to: dev_fix_review
    when: "state.get('review_status') == 'CHANGES_REQUESTED' and state.get('review_fix_attempt', 0) < 2"

  - from: check_review_status
    to: sprint_status
    when: "state.get('review_status') != 'APPROVED' and state.get('review_fix_attempt', 0) >= 2"

  - from: dev_fix_review
    to: increment_review_fix_attempt
  - from: increment_review_fix_attempt
    to: code_review

  # FINAL
  - from: sprint_status
    to: summary
  - from: summary
    to: __end__
