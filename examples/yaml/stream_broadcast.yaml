# examples/yaml/stream_broadcast.yaml
# Broadcast stream to multiple consumers
#
# Demonstrates:
# - stream_mode: broadcast for fan-out
# - Multiple consumers receiving same data
# - Fan-in to collect parallel results
#
# Requirements:
# - Linux/macOS only (Windows not supported)
# - Uses parallel_strategy: process
#
# Run with:
#   tea run examples/yaml/stream_broadcast.yaml

name: stream-broadcast-demo
description: |
  Broadcasts a data stream to multiple consumers in parallel.
  Each consumer processes the same data independently.

settings:
  parallel:
    strategy: process
    streams:
      enabled: true
      buffer_size: 131072  # 128KB for higher throughput

state_schema:
  source_count: int
  word_count: int
  line_count: int
  char_count: int

nodes:
  - name: data_source
    run: |
      import sys

      # Generate text data
      lines = [
        "The quick brown fox jumps over the lazy dog",
        "Pack my box with five dozen liquor jugs",
        "How vexingly quick daft zebras jump",
      ]

      count = 0
      for _ in range(100):  # Repeat for volume
        for line in lines:
          print(line, file=sys.stdout, flush=True)
          count += 1

      return {"source_count": count}
    streams:
      stdout: text_stream

  - name: word_counter
    run: |
      import sys

      total_words = 0
      for line in sys.stdin:
        words = line.strip().split()
        total_words += len(words)

      return {"word_count": total_words}
    streams:
      stdin: text_stream

  - name: line_counter
    run: |
      import sys

      total_lines = 0
      for line in sys.stdin:
        total_lines += 1

      return {"line_count": total_lines}
    streams:
      stdin: text_stream

  - name: char_counter
    run: |
      import sys

      total_chars = 0
      for line in sys.stdin:
        total_chars += len(line.strip())

      return {"char_count": total_chars}
    streams:
      stdin: text_stream

  - name: aggregator
    run: |
      # Merge results from parallel consumers
      return {
        "source_count": parallel_results[0].get("source_count", 0),
        "word_count": parallel_results[1].get("word_count", 0),
        "line_count": parallel_results[2].get("line_count", 0),
        "char_count": parallel_results[3].get("char_count", 0),
      }

edges:
  - from: __start__
    to: data_source
  - from: data_source
    to: [word_counter, line_counter, char_counter]
    parallel: true
    parallel_strategy: process
    stream_mode: broadcast  # All consumers get same data
    fan_in: aggregator
  - from: aggregator
    to: __end__
